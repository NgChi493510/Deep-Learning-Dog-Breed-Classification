{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":85201,"databundleVersionId":9605463,"sourceType":"competition"}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom PIL import Image\nfrom torch.utils.data import Dataset\nimport torch\nimport pandas as pd\nfrom torchvision import transforms\nfrom torch.utils.data import random_split, DataLoader\nimport torch.nn as nn\nimport torchvision.models as models\nimport torch.optim as optim","metadata":{"execution":{"iopub.status.busy":"2024-09-22T11:48:47.282641Z","iopub.execute_input":"2024-09-22T11:48:47.283049Z","iopub.status.idle":"2024-09-22T11:48:47.288474Z","shell.execute_reply.started":"2024-09-22T11:48:47.283012Z","shell.execute_reply":"2024-09-22T11:48:47.287513Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"class ImageDataset(Dataset):\n    def __init__(self, csv_file, root_dir, transform=None, is_test=False):\n        self.data = pd.read_csv(csv_file)\n        self.root_dir = root_dir\n        self.transform = transform\n        self.is_test = is_test\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        if not self.is_test:\n            # Fetch training images using paths from train.csv\n            img_path = os.path.join(self.root_dir, self.data.iloc[idx, 1])\n            image = Image.open(img_path).convert('RGB')\n            label = int(self.data.iloc[idx, 0].split('_')[1]) - 1  # Labeling\n            label = torch.tensor(label)\n            if self.transform:\n                image = self.transform(image)\n            return image, label\n        else:\n            # For test data\n            img_path = os.path.join(self.root_dir, self.data.iloc[idx, 1])\n            image = Image.open(img_path).convert('RGB')\n            if self.transform:\n                image = self.transform(image)\n            return image, self.data.iloc[idx, 0]","metadata":{"execution":{"iopub.status.busy":"2024-09-22T11:48:49.616118Z","iopub.execute_input":"2024-09-22T11:48:49.616544Z","iopub.status.idle":"2024-09-22T11:48:49.626366Z","shell.execute_reply.started":"2024-09-22T11:48:49.616507Z","shell.execute_reply":"2024-09-22T11:48:49.625361Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"# Densenet121","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# Create datasets\ntrain_dataset = ImageDataset(\n    csv_file='/kaggle/input/dl-63-cw-image-classification/train.csv',  # Correct path to train.csv\n    root_dir='/kaggle/input/dl-63-cw-image-classification/train',  # Directory containing images\n    transform=transform\n)\n\ntest_dataset = ImageDataset(\n    csv_file='/kaggle/input/dl-63-cw-image-classification/test.csv',  # Correct path to test.csv\n    root_dir='/kaggle/input/dl-63-cw-image-classification/test/',  # Directory containing test images\n    transform=transform, is_test=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T11:48:54.812990Z","iopub.execute_input":"2024-09-22T11:48:54.813746Z","iopub.status.idle":"2024-09-22T11:48:54.835661Z","shell.execute_reply.started":"2024-09-22T11:48:54.813707Z","shell.execute_reply":"2024-09-22T11:48:54.834880Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"train_size = int(0.8 * len(train_dataset))\nvalid_size = len(train_dataset) - train_size\n\ntrainset, validset = random_split(train_dataset, [train_size, valid_size])\n\n# Create DataLoaders\nbatch_size = 64\ntrain_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(validset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T11:48:59.660118Z","iopub.execute_input":"2024-09-22T11:48:59.660970Z","iopub.status.idle":"2024-09-22T11:48:59.668869Z","shell.execute_reply.started":"2024-09-22T11:48:59.660911Z","shell.execute_reply":"2024-09-22T11:48:59.667942Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"class CustomDenseNet(nn.Module):\n    def __init__(self, num_classes=71):  # Ensure correct number of classes\n        super(CustomDenseNet, self).__init__()\n\n        # Load pre-trained DenseNet121 model\n        self.base_model = models.densenet121(pretrained=True)\n\n        # Freeze all layers if needed (Optional)\n        for param in self.base_model.parameters():\n            param.requires_grad = False\n\n        # Replace the classifier part of the DenseNet\n        in_features = self.base_model.classifier.in_features\n        self.base_model.classifier = nn.Sequential(\n            nn.Linear(in_features, 256),  # Hidden layer\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(256, num_classes)  # Final output layer with num_classes outputs\n        )\n\n    def forward(self, x):\n        x = self.base_model(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-09-22T11:49:06.582287Z","iopub.execute_input":"2024-09-22T11:49:06.582666Z","iopub.status.idle":"2024-09-22T11:49:06.590199Z","shell.execute_reply.started":"2024-09-22T11:49:06.582632Z","shell.execute_reply":"2024-09-22T11:49:06.589172Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = CustomDenseNet(num_classes=71).to(device)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-09-22T11:49:12.823848Z","iopub.execute_input":"2024-09-22T11:49:12.824766Z","iopub.status.idle":"2024-09-22T11:49:13.075999Z","shell.execute_reply.started":"2024-09-22T11:49:12.824708Z","shell.execute_reply":"2024-09-22T11:49:13.075007Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=25):\n    best_val_acc = 0.0\n    for epoch in range(num_epochs):\n        model.train()  # Set to training mode\n        running_loss, running_corrects = 0.0, 0\n\n        # Training loop\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            _, preds = torch.max(outputs, 1)\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n\n        epoch_loss = running_loss / len(train_loader.dataset)\n        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n        print(f'Training - Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n\n        # Validation loop\n        model.eval()  # Set to evaluation mode\n        val_corrects = 0\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                _, preds = torch.max(outputs, 1)\n                val_corrects += torch.sum(preds == labels.data)\n\n        val_acc = val_corrects.double() / len(val_loader.dataset)\n        print(f'Validation Accuracy: {val_acc:.4f}')\n\n        # Save the best model based on validation accuracy\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), 'best_model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-09-22T11:49:17.164237Z","iopub.execute_input":"2024-09-22T11:49:17.165256Z","iopub.status.idle":"2024-09-22T11:49:17.179141Z","shell.execute_reply.started":"2024-09-22T11:49:17.165198Z","shell.execute_reply":"2024-09-22T11:49:17.178073Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"train_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=15)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T11:56:06.877457Z","iopub.execute_input":"2024-09-22T11:56:06.877836Z","iopub.status.idle":"2024-09-22T12:06:40.632560Z","shell.execute_reply.started":"2024-09-22T11:56:06.877800Z","shell.execute_reply":"2024-09-22T12:06:40.631446Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Training - Epoch 1/15, Loss: 0.3287, Accuracy: 0.8914\nValidation Accuracy: 0.8950\nTraining - Epoch 2/15, Loss: 0.3086, Accuracy: 0.9061\nValidation Accuracy: 0.8937\nTraining - Epoch 3/15, Loss: 0.2952, Accuracy: 0.9043\nValidation Accuracy: 0.8912\nTraining - Epoch 4/15, Loss: 0.2832, Accuracy: 0.9050\nValidation Accuracy: 0.8893\nTraining - Epoch 5/15, Loss: 0.2644, Accuracy: 0.9147\nValidation Accuracy: 0.9038\nTraining - Epoch 6/15, Loss: 0.2545, Accuracy: 0.9201\nValidation Accuracy: 0.8874\nTraining - Epoch 7/15, Loss: 0.2524, Accuracy: 0.9171\nValidation Accuracy: 0.8887\nTraining - Epoch 8/15, Loss: 0.2357, Accuracy: 0.9261\nValidation Accuracy: 0.9063\nTraining - Epoch 9/15, Loss: 0.2206, Accuracy: 0.9294\nValidation Accuracy: 0.8969\nTraining - Epoch 10/15, Loss: 0.2008, Accuracy: 0.9334\nValidation Accuracy: 0.8950\nTraining - Epoch 11/15, Loss: 0.1950, Accuracy: 0.9371\nValidation Accuracy: 0.8937\nTraining - Epoch 12/15, Loss: 0.2074, Accuracy: 0.9284\nValidation Accuracy: 0.8950\nTraining - Epoch 13/15, Loss: 0.1979, Accuracy: 0.9390\nValidation Accuracy: 0.8981\nTraining - Epoch 14/15, Loss: 0.1816, Accuracy: 0.9388\nValidation Accuracy: 0.8918\nTraining - Epoch 15/15, Loss: 0.1770, Accuracy: 0.9405\nValidation Accuracy: 0.8937\n","output_type":"stream"}]},{"cell_type":"code","source":"for param in model.base_model.features[-1:].parameters():  \n    param.requires_grad = True\n\n# Re-define optimizer for fine-tuning\noptimizer = optim.SGD(model.parameters(), lr=0.001)\n\n# Fine-tune the model\ntrain_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=15)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T12:06:51.323499Z","iopub.execute_input":"2024-09-22T12:06:51.323857Z","iopub.status.idle":"2024-09-22T12:17:23.293410Z","shell.execute_reply.started":"2024-09-22T12:06:51.323824Z","shell.execute_reply":"2024-09-22T12:17:23.292400Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Training - Epoch 1/15, Loss: 0.1539, Accuracy: 0.9515\nValidation Accuracy: 0.8943\nTraining - Epoch 2/15, Loss: 0.1494, Accuracy: 0.9511\nValidation Accuracy: 0.8962\nTraining - Epoch 3/15, Loss: 0.1428, Accuracy: 0.9547\nValidation Accuracy: 0.8975\nTraining - Epoch 4/15, Loss: 0.1426, Accuracy: 0.9547\nValidation Accuracy: 0.8931\nTraining - Epoch 5/15, Loss: 0.1448, Accuracy: 0.9512\nValidation Accuracy: 0.8987\nTraining - Epoch 6/15, Loss: 0.1382, Accuracy: 0.9531\nValidation Accuracy: 0.9019\nTraining - Epoch 7/15, Loss: 0.1356, Accuracy: 0.9574\nValidation Accuracy: 0.9006\nTraining - Epoch 8/15, Loss: 0.1408, Accuracy: 0.9547\nValidation Accuracy: 0.8994\nTraining - Epoch 9/15, Loss: 0.1396, Accuracy: 0.9556\nValidation Accuracy: 0.8962\nTraining - Epoch 10/15, Loss: 0.1287, Accuracy: 0.9630\nValidation Accuracy: 0.8994\nTraining - Epoch 11/15, Loss: 0.1355, Accuracy: 0.9585\nValidation Accuracy: 0.8969\nTraining - Epoch 12/15, Loss: 0.1281, Accuracy: 0.9607\nValidation Accuracy: 0.8943\nTraining - Epoch 13/15, Loss: 0.1349, Accuracy: 0.9536\nValidation Accuracy: 0.8981\nTraining - Epoch 14/15, Loss: 0.1367, Accuracy: 0.9548\nValidation Accuracy: 0.8981\nTraining - Epoch 15/15, Loss: 0.1290, Accuracy: 0.9602\nValidation Accuracy: 0.9006\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate_model_on_test_set(model, test_loader, device, class_mapping):\n    model.eval()\n    predictions = []\n    ids = []\n    \n    with torch.no_grad():\n        for images, image_ids in test_loader:\n            images = images.to(device)\n            outputs = model(images)\n            _, predicted_classes = torch.max(outputs, 1)\n            \n            predicted_classes = [class_mapping[p.item()] for p in predicted_classes]\n            \n        \n            predictions.extend(predicted_classes)\n            ids.extend(image_ids)  # image_ids chính là các ID từ file test.csv\n    \n    return ids, predictions\n\nclass_mapping = {i: f'class_{i+1}' for i in range(71)}","metadata":{"execution":{"iopub.status.busy":"2024-09-22T12:17:29.784330Z","iopub.execute_input":"2024-09-22T12:17:29.785093Z","iopub.status.idle":"2024-09-22T12:17:29.792293Z","shell.execute_reply.started":"2024-09-22T12:17:29.785053Z","shell.execute_reply":"2024-09-22T12:17:29.791361Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"ids, predictions = evaluate_model_on_test_set(model, test_loader, device, class_mapping)\nrenamed_ids = list(range(len(ids)))\nresults = pd.DataFrame({\n    'ID': renamed_ids, \n    'TARGET': predictions \n})\n\nresults.to_csv('submission8.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T12:17:34.579649Z","iopub.execute_input":"2024-09-22T12:17:34.580033Z","iopub.status.idle":"2024-09-22T12:17:43.179006Z","shell.execute_reply.started":"2024-09-22T12:17:34.579997Z","shell.execute_reply":"2024-09-22T12:17:43.178016Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"# Resnet50","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# Create datasets\ntrain_dataset = ImageDataset(\n    csv_file='/kaggle/input/dl-63-cw-image-classification/train.csv',  # Correct path to train.csv\n    root_dir='/kaggle/input/dl-63-cw-image-classification/train',  # Directory containing images\n    transform=transform\n)\n\ntest_dataset = ImageDataset(\n    csv_file='/kaggle/input/dl-63-cw-image-classification/test.csv',  # Correct path to test.csv\n    root_dir='/kaggle/input/dl-63-cw-image-classification/test/',  # Directory containing test images\n    transform=transform, is_test=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T23:21:57.088219Z","iopub.execute_input":"2024-09-21T23:21:57.088597Z","iopub.status.idle":"2024-09-21T23:21:57.132187Z","shell.execute_reply.started":"2024-09-21T23:21:57.088560Z","shell.execute_reply":"2024-09-21T23:21:57.131211Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_size = int(0.8 * len(train_dataset))\nvalid_size = len(train_dataset) - train_size\n\ntrainset, validset = random_split(train_dataset, [train_size, valid_size])\n\n# Create DataLoaders\nbatch_size = 32\ntrain_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(validset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T23:21:59.367338Z","iopub.execute_input":"2024-09-21T23:21:59.367714Z","iopub.status.idle":"2024-09-21T23:21:59.398698Z","shell.execute_reply.started":"2024-09-21T23:21:59.367678Z","shell.execute_reply":"2024-09-21T23:21:59.397772Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class CustomResNet50(nn.Module):\n    def __init__(self, num_classes=71):\n        super(CustomResNet50, self).__init__()\n\n        # Load pre-trained ResNet50 model\n        self.base_model = models.resnet50(pretrained=True)\n\n        # Freeze the feature extraction layers\n        for param in self.base_model.parameters():\n            param.requires_grad = False\n\n        # Modify the classifier (fully connected layer)\n        in_features = self.base_model.fc.in_features\n        self.base_model.fc = nn.Sequential(\n            nn.Linear(in_features, 256),  # Fully connected layer from in_features to 256\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(256, num_classes)  # Final output layer with num_classes outputs\n        )\n\n    def forward(self, x):\n        x = self.base_model(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-09-21T23:22:01.848571Z","iopub.execute_input":"2024-09-21T23:22:01.849433Z","iopub.status.idle":"2024-09-21T23:22:01.858131Z","shell.execute_reply.started":"2024-09-21T23:22:01.849383Z","shell.execute_reply":"2024-09-21T23:22:01.857091Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = CustomResNet50(num_classes=71).to(device)\n\noptimizer = optim.RMSprop(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-09-21T23:22:05.024602Z","iopub.execute_input":"2024-09-21T23:22:05.025580Z","iopub.status.idle":"2024-09-21T23:22:06.570870Z","shell.execute_reply.started":"2024-09-21T23:22:05.025527Z","shell.execute_reply":"2024-09-21T23:22:06.569881Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 167MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"def train_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=25):\n    best_val_acc = 0.0\n    for epoch in range(num_epochs):\n        model.train()  # Set to training mode\n        running_loss, running_corrects = 0.0, 0\n\n        # Training loop\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            _, preds = torch.max(outputs, 1)\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n\n        epoch_loss = running_loss / len(train_loader.dataset)\n        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n        print(f'Training - Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n\n        # Validation loop\n        model.eval()  # Set to evaluation mode\n        val_corrects = 0\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                _, preds = torch.max(outputs, 1)\n                val_corrects += torch.sum(preds == labels.data)\n\n        val_acc = val_corrects.double() / len(val_loader.dataset)\n        print(f'Validation Accuracy: {val_acc:.4f}')\n\n        # Save the best model based on validation accuracy\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), 'best_model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-09-21T23:22:09.527430Z","iopub.execute_input":"2024-09-21T23:22:09.528264Z","iopub.status.idle":"2024-09-21T23:22:09.538946Z","shell.execute_reply.started":"2024-09-21T23:22:09.528222Z","shell.execute_reply":"2024-09-21T23:22:09.538007Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T23:22:12.765715Z","iopub.execute_input":"2024-09-21T23:22:12.766162Z","iopub.status.idle":"2024-09-21T23:28:43.702368Z","shell.execute_reply.started":"2024-09-21T23:22:12.766122Z","shell.execute_reply":"2024-09-21T23:28:43.701357Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Training - Epoch 1/10, Loss: 3.0821, Accuracy: 0.2637\nValidation Accuracy: 0.7597\nTraining - Epoch 2/10, Loss: 1.5688, Accuracy: 0.5459\nValidation Accuracy: 0.8591\nTraining - Epoch 3/10, Loss: 1.2159, Accuracy: 0.6353\nValidation Accuracy: 0.8516\nTraining - Epoch 4/10, Loss: 1.0459, Accuracy: 0.6757\nValidation Accuracy: 0.8818\nTraining - Epoch 5/10, Loss: 0.9307, Accuracy: 0.7048\nValidation Accuracy: 0.8862\nTraining - Epoch 6/10, Loss: 0.8723, Accuracy: 0.7267\nValidation Accuracy: 0.8610\nTraining - Epoch 7/10, Loss: 0.8301, Accuracy: 0.7354\nValidation Accuracy: 0.8811\nTraining - Epoch 8/10, Loss: 0.7700, Accuracy: 0.7602\nValidation Accuracy: 0.8893\nTraining - Epoch 9/10, Loss: 0.7446, Accuracy: 0.7667\nValidation Accuracy: 0.8918\nTraining - Epoch 10/10, Loss: 0.7298, Accuracy: 0.7613\nValidation Accuracy: 0.8975\n","output_type":"stream"}]},{"cell_type":"code","source":"for param in model.base_model.layer4.parameters():  # layer4 is the last block in ResNet50\n    param.requires_grad = True\n\n# Re-define optimizer for fine-tuning\noptimizer = optim.SGD(model.parameters(), lr=0.001)\n\n# Fine-tune the model\ntrain_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T23:30:02.546172Z","iopub.execute_input":"2024-09-21T23:30:02.546540Z","iopub.status.idle":"2024-09-21T23:37:13.369218Z","shell.execute_reply.started":"2024-09-21T23:30:02.546508Z","shell.execute_reply":"2024-09-21T23:37:13.368424Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Training - Epoch 1/10, Loss: 0.6653, Accuracy: 0.7851\nValidation Accuracy: 0.9063\nTraining - Epoch 2/10, Loss: 0.6287, Accuracy: 0.8046\nValidation Accuracy: 0.9075\nTraining - Epoch 3/10, Loss: 0.5602, Accuracy: 0.8243\nValidation Accuracy: 0.9082\nTraining - Epoch 4/10, Loss: 0.5553, Accuracy: 0.8217\nValidation Accuracy: 0.9126\nTraining - Epoch 5/10, Loss: 0.5290, Accuracy: 0.8254\nValidation Accuracy: 0.9145\nTraining - Epoch 6/10, Loss: 0.4985, Accuracy: 0.8390\nValidation Accuracy: 0.9151\nTraining - Epoch 7/10, Loss: 0.4821, Accuracy: 0.8438\nValidation Accuracy: 0.9151\nTraining - Epoch 8/10, Loss: 0.4665, Accuracy: 0.8466\nValidation Accuracy: 0.9195\nTraining - Epoch 9/10, Loss: 0.4562, Accuracy: 0.8516\nValidation Accuracy: 0.9214\nTraining - Epoch 10/10, Loss: 0.4414, Accuracy: 0.8499\nValidation Accuracy: 0.9220\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate_model_on_test_set(model, test_loader, device, class_mapping):\n    model.eval()\n    predictions = []\n    ids = []\n    \n    with torch.no_grad():\n        for images, image_ids in test_loader:\n            images = images.to(device)\n            outputs = model(images)\n            _, predicted_classes = torch.max(outputs, 1)\n            \n            # Chuyển predicted_classes từ số thành tên class\n            predicted_classes = [class_mapping[p.item()] for p in predicted_classes]\n            \n            # Lưu lại image_ids từ test_loader thay vì sử dụng tensor index\n            predictions.extend(predicted_classes)\n            ids.extend(image_ids)  # image_ids chính là các ID từ file test.csv\n    \n    return ids, predictions\n\n# Map số index về class_name\nclass_mapping = {i: f'class_{i+1}' for i in range(71)}","metadata":{"execution":{"iopub.status.busy":"2024-09-21T23:37:29.594622Z","iopub.execute_input":"2024-09-21T23:37:29.595490Z","iopub.status.idle":"2024-09-21T23:37:29.602510Z","shell.execute_reply.started":"2024-09-21T23:37:29.595451Z","shell.execute_reply":"2024-09-21T23:37:29.601572Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"ids, predictions = evaluate_model_on_test_set(model, test_loader, device, class_mapping)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T23:37:37.905148Z","iopub.execute_input":"2024-09-21T23:37:37.905879Z","iopub.status.idle":"2024-09-21T23:37:49.010649Z","shell.execute_reply.started":"2024-09-21T23:37:37.905838Z","shell.execute_reply":"2024-09-21T23:37:49.009776Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"renamed_ids = list(range(len(ids)))","metadata":{"execution":{"iopub.status.busy":"2024-09-21T23:38:08.513477Z","iopub.execute_input":"2024-09-21T23:38:08.514201Z","iopub.status.idle":"2024-09-21T23:38:08.518374Z","shell.execute_reply.started":"2024-09-21T23:38:08.514162Z","shell.execute_reply":"2024-09-21T23:38:08.517402Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"results = pd.DataFrame({\n    'ID': renamed_ids, \n    'TARGET': predictions \n})\n\nresults.to_csv('submission2.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T23:38:20.048786Z","iopub.execute_input":"2024-09-21T23:38:20.049444Z","iopub.status.idle":"2024-09-21T23:38:20.066488Z","shell.execute_reply.started":"2024-09-21T23:38:20.049396Z","shell.execute_reply":"2024-09-21T23:38:20.065539Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"results","metadata":{"execution":{"iopub.status.busy":"2024-09-21T23:38:26.721653Z","iopub.execute_input":"2024-09-21T23:38:26.722261Z","iopub.status.idle":"2024-09-21T23:38:26.752208Z","shell.execute_reply.started":"2024-09-21T23:38:26.722222Z","shell.execute_reply":"2024-09-21T23:38:26.751322Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"        ID    TARGET\n0        0  class_58\n1        1  class_58\n2        2   class_7\n3        3  class_17\n4        4  class_71\n...    ...       ...\n1395  1395  class_69\n1396  1396  class_51\n1397  1397  class_65\n1398  1398  class_49\n1399  1399  class_55\n\n[1400 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>TARGET</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>class_58</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>class_58</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>class_7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>class_17</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>class_71</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1395</th>\n      <td>1395</td>\n      <td>class_69</td>\n    </tr>\n    <tr>\n      <th>1396</th>\n      <td>1396</td>\n      <td>class_51</td>\n    </tr>\n    <tr>\n      <th>1397</th>\n      <td>1397</td>\n      <td>class_65</td>\n    </tr>\n    <tr>\n      <th>1398</th>\n      <td>1398</td>\n      <td>class_49</td>\n    </tr>\n    <tr>\n      <th>1399</th>\n      <td>1399</td>\n      <td>class_55</td>\n    </tr>\n  </tbody>\n</table>\n<p>1400 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Resnet 50_Version 2","metadata":{}},{"cell_type":"code","source":"# transform = transforms.Compose([\n#     transforms.Resize((224, 224)),\n#     transforms.ToTensor(),\n#     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n# ])\n\ntransform = transforms.Compose([\n    transforms.Resize((256, 256)),  \n    transforms.CenterCrop(224),     \n    transforms.RandomHorizontalFlip(), \n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])","metadata":{"execution":{"iopub.status.busy":"2024-09-22T05:24:01.610211Z","iopub.execute_input":"2024-09-22T05:24:01.610613Z","iopub.status.idle":"2024-09-22T05:24:01.616458Z","shell.execute_reply.started":"2024-09-22T05:24:01.610575Z","shell.execute_reply":"2024-09-22T05:24:01.615494Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"\n# Create datasets\ntrain_dataset = ImageDataset(\n    csv_file='/kaggle/input/dl-63-cw-image-classification/train.csv',  # Correct path to train.csv\n    root_dir='/kaggle/input/dl-63-cw-image-classification/train',  # Directory containing images\n    transform=transform\n)\n\ntest_dataset = ImageDataset(\n    csv_file='/kaggle/input/dl-63-cw-image-classification/test.csv',  # Correct path to test.csv\n    root_dir='/kaggle/input/dl-63-cw-image-classification/test/',  # Directory containing test images\n    transform=transform, is_test=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T05:24:04.311952Z","iopub.execute_input":"2024-09-22T05:24:04.312344Z","iopub.status.idle":"2024-09-22T05:24:04.328873Z","shell.execute_reply.started":"2024-09-22T05:24:04.312307Z","shell.execute_reply":"2024-09-22T05:24:04.327927Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"train_size = int(0.8 * len(train_dataset))\nvalid_size = len(train_dataset) - train_size\n\ntrainset, validset = random_split(train_dataset, [train_size, valid_size])\n\n# Create DataLoaders\nbatch_size = 32\ntrain_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(validset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T05:24:07.080207Z","iopub.execute_input":"2024-09-22T05:24:07.080632Z","iopub.status.idle":"2024-09-22T05:24:07.087634Z","shell.execute_reply.started":"2024-09-22T05:24:07.080591Z","shell.execute_reply":"2024-09-22T05:24:07.086752Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"class CustomResNet50(nn.Module):\n    def __init__(self, num_classes=71):\n        super(CustomResNet50, self).__init__()\n\n        # Load pre-trained ResNet50 model\n        self.base_model = models.resnet50(pretrained=True)\n\n        # Freeze the feature extraction layers\n        for param in self.base_model.parameters():\n            param.requires_grad = False\n\n        # Modify the classifier (fully connected layer)\n        in_features = self.base_model.fc.in_features\n        self.base_model.fc = nn.Sequential(\n            nn.Linear(in_features, 256),  # Fully connected layer from in_features to 256\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(256, num_classes)  # Final output layer with num_classes outputs\n        )\n\n    def forward(self, x):\n        x = self.base_model(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-09-22T05:24:09.824478Z","iopub.execute_input":"2024-09-22T05:24:09.825339Z","iopub.status.idle":"2024-09-22T05:24:09.832373Z","shell.execute_reply.started":"2024-09-22T05:24:09.825298Z","shell.execute_reply":"2024-09-22T05:24:09.831303Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = CustomResNet50(num_classes=71).to(device)\n\noptimizer = optim.RMSprop(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-09-22T05:24:12.617495Z","iopub.execute_input":"2024-09-22T05:24:12.617871Z","iopub.status.idle":"2024-09-22T05:24:13.107950Z","shell.execute_reply.started":"2024-09-22T05:24:12.617830Z","shell.execute_reply":"2024-09-22T05:24:13.106968Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=25):\n    best_val_acc = 0.0\n    for epoch in range(num_epochs):\n        model.train()  # Set to training mode\n        running_loss, running_corrects = 0.0, 0\n\n        # Training loop\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            _, preds = torch.max(outputs, 1)\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n\n        epoch_loss = running_loss / len(train_loader.dataset)\n        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n        print(f'Training - Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n\n        # Validation loop\n        model.eval()  # Set to evaluation mode\n        val_corrects = 0\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                _, preds = torch.max(outputs, 1)\n                val_corrects += torch.sum(preds == labels.data)\n\n        val_acc = val_corrects.double() / len(val_loader.dataset)\n        print(f'Validation Accuracy: {val_acc:.4f}')\n\n        # Save the best model based on validation accuracy\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), 'best_model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-09-22T05:24:15.377215Z","iopub.execute_input":"2024-09-22T05:24:15.377877Z","iopub.status.idle":"2024-09-22T05:24:15.388309Z","shell.execute_reply.started":"2024-09-22T05:24:15.377838Z","shell.execute_reply":"2024-09-22T05:24:15.387321Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"train_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=15)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T05:27:37.592044Z","iopub.execute_input":"2024-09-22T05:27:37.592740Z","iopub.status.idle":"2024-09-22T05:39:00.389252Z","shell.execute_reply.started":"2024-09-22T05:27:37.592701Z","shell.execute_reply":"2024-09-22T05:39:00.388075Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"Training - Epoch 1/15, Loss: 1.1945, Accuracy: 0.6361\nValidation Accuracy: 0.8623\nTraining - Epoch 2/15, Loss: 1.1307, Accuracy: 0.6487\nValidation Accuracy: 0.8296\nTraining - Epoch 3/15, Loss: 1.0578, Accuracy: 0.6704\nValidation Accuracy: 0.8692\nTraining - Epoch 4/15, Loss: 1.0025, Accuracy: 0.6858\nValidation Accuracy: 0.8736\nTraining - Epoch 5/15, Loss: 0.9555, Accuracy: 0.6956\nValidation Accuracy: 0.8654\nTraining - Epoch 6/15, Loss: 0.9250, Accuracy: 0.7097\nValidation Accuracy: 0.8748\nTraining - Epoch 7/15, Loss: 0.8955, Accuracy: 0.7132\nValidation Accuracy: 0.8597\nTraining - Epoch 8/15, Loss: 0.8757, Accuracy: 0.7173\nValidation Accuracy: 0.8616\nTraining - Epoch 9/15, Loss: 0.8711, Accuracy: 0.7201\nValidation Accuracy: 0.8780\nTraining - Epoch 10/15, Loss: 0.8268, Accuracy: 0.7340\nValidation Accuracy: 0.8767\nTraining - Epoch 11/15, Loss: 0.8182, Accuracy: 0.7360\nValidation Accuracy: 0.8805\nTraining - Epoch 12/15, Loss: 0.8275, Accuracy: 0.7399\nValidation Accuracy: 0.8780\nTraining - Epoch 13/15, Loss: 0.8087, Accuracy: 0.7410\nValidation Accuracy: 0.8742\nTraining - Epoch 14/15, Loss: 0.7930, Accuracy: 0.7396\nValidation Accuracy: 0.8704\nTraining - Epoch 15/15, Loss: 0.8103, Accuracy: 0.7442\nValidation Accuracy: 0.8805\n","output_type":"stream"}]},{"cell_type":"code","source":"for param in model.base_model.layer4.parameters():  # layer4 is the last block in ResNet50\n    param.requires_grad = True\n\n# Re-define optimizer for fine-tuning\noptimizer = optim.SGD(model.parameters(), lr=0.001)\n\n# Fine-tune the model\ntrain_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=15)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T05:39:09.533016Z","iopub.execute_input":"2024-09-22T05:39:09.533383Z","iopub.status.idle":"2024-09-22T05:52:09.766568Z","shell.execute_reply.started":"2024-09-22T05:39:09.533347Z","shell.execute_reply":"2024-09-22T05:52:09.765559Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Training - Epoch 1/15, Loss: 0.7439, Accuracy: 0.7588\nValidation Accuracy: 0.8937\nTraining - Epoch 2/15, Loss: 0.6815, Accuracy: 0.7816\nValidation Accuracy: 0.8899\nTraining - Epoch 3/15, Loss: 0.6258, Accuracy: 0.7936\nValidation Accuracy: 0.8918\nTraining - Epoch 4/15, Loss: 0.5995, Accuracy: 0.8038\nValidation Accuracy: 0.9025\nTraining - Epoch 5/15, Loss: 0.5535, Accuracy: 0.8143\nValidation Accuracy: 0.8906\nTraining - Epoch 6/15, Loss: 0.5557, Accuracy: 0.8158\nValidation Accuracy: 0.8975\nTraining - Epoch 7/15, Loss: 0.5236, Accuracy: 0.8254\nValidation Accuracy: 0.8981\nTraining - Epoch 8/15, Loss: 0.5299, Accuracy: 0.8254\nValidation Accuracy: 0.8950\nTraining - Epoch 9/15, Loss: 0.4961, Accuracy: 0.8302\nValidation Accuracy: 0.9044\nTraining - Epoch 10/15, Loss: 0.4906, Accuracy: 0.8342\nValidation Accuracy: 0.9044\nTraining - Epoch 11/15, Loss: 0.4788, Accuracy: 0.8417\nValidation Accuracy: 0.9050\nTraining - Epoch 12/15, Loss: 0.4696, Accuracy: 0.8409\nValidation Accuracy: 0.9063\nTraining - Epoch 13/15, Loss: 0.4425, Accuracy: 0.8531\nValidation Accuracy: 0.9013\nTraining - Epoch 14/15, Loss: 0.4486, Accuracy: 0.8565\nValidation Accuracy: 0.9000\nTraining - Epoch 15/15, Loss: 0.4474, Accuracy: 0.8524\nValidation Accuracy: 0.9044\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate_model_on_test_set(model, test_loader, device, class_mapping):\n    model.eval()\n    predictions = []\n    ids = []\n    \n    with torch.no_grad():\n        for images, image_ids in test_loader:\n            images = images.to(device)\n            outputs = model(images)\n            _, predicted_classes = torch.max(outputs, 1)\n            \n            # Chuyển predicted_classes từ số thành tên class\n            predicted_classes = [class_mapping[p.item()] for p in predicted_classes]\n            \n            # Lưu lại image_ids từ test_loader thay vì sử dụng tensor index\n            predictions.extend(predicted_classes)\n            ids.extend(image_ids)  # image_ids chính là các ID từ file test.csv\n    \n    return ids, predictions\n\n# Map số index về class_name\nclass_mapping = {i: f'class_{i+1}' for i in range(71)}","metadata":{"execution":{"iopub.status.busy":"2024-09-22T05:52:15.686808Z","iopub.execute_input":"2024-09-22T05:52:15.687722Z","iopub.status.idle":"2024-09-22T05:52:15.695391Z","shell.execute_reply.started":"2024-09-22T05:52:15.687670Z","shell.execute_reply":"2024-09-22T05:52:15.694311Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"ids, predictions = evaluate_model_on_test_set(model, test_loader, device, class_mapping)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T05:52:22.922427Z","iopub.execute_input":"2024-09-22T05:52:22.922861Z","iopub.status.idle":"2024-09-22T05:52:32.476792Z","shell.execute_reply.started":"2024-09-22T05:52:22.922822Z","shell.execute_reply":"2024-09-22T05:52:32.475898Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"renamed_ids = list(range(len(ids)))","metadata":{"execution":{"iopub.status.busy":"2024-09-22T05:52:35.795226Z","iopub.execute_input":"2024-09-22T05:52:35.795605Z","iopub.status.idle":"2024-09-22T05:52:35.801760Z","shell.execute_reply.started":"2024-09-22T05:52:35.795571Z","shell.execute_reply":"2024-09-22T05:52:35.800701Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"results = pd.DataFrame({\n    'ID': renamed_ids, \n    'TARGET': predictions \n})\n\nresults.to_csv('submission5.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T05:52:38.770866Z","iopub.execute_input":"2024-09-22T05:52:38.771619Z","iopub.status.idle":"2024-09-22T05:52:38.780802Z","shell.execute_reply.started":"2024-09-22T05:52:38.771578Z","shell.execute_reply":"2024-09-22T05:52:38.779868Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"# EfficientNet","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# Create datasets\ntrain_dataset = ImageDataset(\n    csv_file='/kaggle/input/dl-63-cw-image-classification/train.csv',  # Correct path to train.csv\n    root_dir='/kaggle/input/dl-63-cw-image-classification/train',  # Directory containing images\n    transform=transform\n)\n\ntest_dataset = ImageDataset(\n    csv_file='/kaggle/input/dl-63-cw-image-classification/test.csv',  # Correct path to test.csv\n    root_dir='/kaggle/input/dl-63-cw-image-classification/test/',  # Directory containing test images\n    transform=transform, is_test=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-22T06:22:19.835546Z","iopub.execute_input":"2024-09-22T06:22:19.835955Z","iopub.status.idle":"2024-09-22T06:22:19.856344Z","shell.execute_reply.started":"2024-09-22T06:22:19.835917Z","shell.execute_reply":"2024-09-22T06:22:19.855494Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"train_size = int(0.8 * len(train_dataset))\nvalid_size = len(train_dataset) - train_size\n\ntrainset, validset = random_split(train_dataset, [train_size, valid_size])\n\n# Create DataLoaders\nbatch_size = 32\ntrain_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(validset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T06:22:23.592770Z","iopub.execute_input":"2024-09-22T06:22:23.593735Z","iopub.status.idle":"2024-09-22T06:22:23.600126Z","shell.execute_reply.started":"2024-09-22T06:22:23.593687Z","shell.execute_reply":"2024-09-22T06:22:23.599232Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"class CustomEfficientNet(nn.Module):\n    def __init__(self, num_classes=71):\n        super(CustomEfficientNet, self).__init__()\n\n        # Load EfficientNet-B0 pre-trained model\n        self.base_model = models.efficientnet_b1(pretrained=True)\n        \n        # Modify the final fully connected layer\n        in_features = self.base_model.classifier[1].in_features\n        self.base_model.classifier = nn.Sequential(\n            nn.Linear(in_features, 256),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(256, num_classes)\n        )\n\n    def forward(self, x):\n        return self.base_model(x)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T06:22:26.610342Z","iopub.execute_input":"2024-09-22T06:22:26.610705Z","iopub.status.idle":"2024-09-22T06:22:26.617727Z","shell.execute_reply.started":"2024-09-22T06:22:26.610666Z","shell.execute_reply":"2024-09-22T06:22:26.616655Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = CustomEfficientNet(num_classes=71).to(device)\n\noptimizer = optim.RMSprop(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-09-22T06:22:29.810977Z","iopub.execute_input":"2024-09-22T06:22:29.811680Z","iopub.status.idle":"2024-09-22T06:22:31.245195Z","shell.execute_reply.started":"2024-09-22T06:22:29.811638Z","shell.execute_reply":"2024-09-22T06:22:31.244183Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B1_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B1_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/efficientnet_b1_rwightman-bac287d4.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b1_rwightman-bac287d4.pth\n100%|██████████| 30.1M/30.1M [00:00<00:00, 49.0MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=25):\n    best_val_acc = 0.0\n    for epoch in range(num_epochs):\n        model.train()  # Set to training mode\n        running_loss, running_corrects = 0.0, 0\n\n        # Training loop\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            _, preds = torch.max(outputs, 1)\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n\n        epoch_loss = running_loss / len(train_loader.dataset)\n        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n        print(f'Training - Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n\n        # Validation loop\n        model.eval()  # Set to evaluation mode\n        val_corrects = 0\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                _, preds = torch.max(outputs, 1)\n                val_corrects += torch.sum(preds == labels.data)\n\n        val_acc = val_corrects.double() / len(val_loader.dataset)\n        print(f'Validation Accuracy: {val_acc:.4f}')\n\n        # Save the best model based on validation accuracy\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), 'best_model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-09-22T06:22:34.356116Z","iopub.execute_input":"2024-09-22T06:22:34.356956Z","iopub.status.idle":"2024-09-22T06:22:34.368618Z","shell.execute_reply.started":"2024-09-22T06:22:34.356900Z","shell.execute_reply":"2024-09-22T06:22:34.367674Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"train_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=20)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T06:22:38.899454Z","iopub.execute_input":"2024-09-22T06:22:38.900142Z","iopub.status.idle":"2024-09-22T06:42:34.455230Z","shell.execute_reply.started":"2024-09-22T06:22:38.900100Z","shell.execute_reply":"2024-09-22T06:42:34.454144Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"Training - Epoch 1/20, Loss: 2.7936, Accuracy: 0.2851\nValidation Accuracy: 0.5748\nTraining - Epoch 2/20, Loss: 1.2039, Accuracy: 0.6403\nValidation Accuracy: 0.7063\nTraining - Epoch 3/20, Loss: 0.7447, Accuracy: 0.7697\nValidation Accuracy: 0.7396\nTraining - Epoch 4/20, Loss: 0.5532, Accuracy: 0.8307\nValidation Accuracy: 0.7893\nTraining - Epoch 5/20, Loss: 0.4303, Accuracy: 0.8644\nValidation Accuracy: 0.7748\nTraining - Epoch 6/20, Loss: 0.3600, Accuracy: 0.8897\nValidation Accuracy: 0.7912\nTraining - Epoch 7/20, Loss: 0.3021, Accuracy: 0.9056\nValidation Accuracy: 0.7616\nTraining - Epoch 8/20, Loss: 0.2832, Accuracy: 0.9133\nValidation Accuracy: 0.8151\nTraining - Epoch 9/20, Loss: 0.2447, Accuracy: 0.9257\nValidation Accuracy: 0.7887\nTraining - Epoch 10/20, Loss: 0.2480, Accuracy: 0.9246\nValidation Accuracy: 0.8107\nTraining - Epoch 11/20, Loss: 0.2351, Accuracy: 0.9308\nValidation Accuracy: 0.7881\nTraining - Epoch 12/20, Loss: 0.2106, Accuracy: 0.9402\nValidation Accuracy: 0.7673\nTraining - Epoch 13/20, Loss: 0.2118, Accuracy: 0.9353\nValidation Accuracy: 0.7811\nTraining - Epoch 14/20, Loss: 0.1696, Accuracy: 0.9470\nValidation Accuracy: 0.7761\nTraining - Epoch 15/20, Loss: 0.1840, Accuracy: 0.9437\nValidation Accuracy: 0.8189\nTraining - Epoch 16/20, Loss: 0.1801, Accuracy: 0.9463\nValidation Accuracy: 0.8189\nTraining - Epoch 17/20, Loss: 0.1823, Accuracy: 0.9487\nValidation Accuracy: 0.8151\nTraining - Epoch 18/20, Loss: 0.1542, Accuracy: 0.9542\nValidation Accuracy: 0.7925\nTraining - Epoch 19/20, Loss: 0.1485, Accuracy: 0.9542\nValidation Accuracy: 0.8050\nTraining - Epoch 20/20, Loss: 0.1627, Accuracy: 0.9520\nValidation Accuracy: 0.8239\n","output_type":"stream"}]},{"cell_type":"code","source":"for param in model.base_model.features[6:].parameters():\n    param.requires_grad = True\n\n# Re-define optimizer for fine-tuning\noptimizer = optim.SGD(model.parameters(), lr=0.001)\n\n# Fine-tune the model\ntrain_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=20)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T06:43:18.824742Z","iopub.execute_input":"2024-09-22T06:43:18.825481Z","iopub.status.idle":"2024-09-22T07:03:10.016530Z","shell.execute_reply.started":"2024-09-22T06:43:18.825435Z","shell.execute_reply":"2024-09-22T07:03:10.015664Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"Training - Epoch 1/20, Loss: 0.0985, Accuracy: 0.9722\nValidation Accuracy: 0.8277\nTraining - Epoch 2/20, Loss: 0.0851, Accuracy: 0.9747\nValidation Accuracy: 0.8308\nTraining - Epoch 3/20, Loss: 0.0923, Accuracy: 0.9731\nValidation Accuracy: 0.8314\nTraining - Epoch 4/20, Loss: 0.0788, Accuracy: 0.9767\nValidation Accuracy: 0.8314\nTraining - Epoch 5/20, Loss: 0.0839, Accuracy: 0.9755\nValidation Accuracy: 0.8340\nTraining - Epoch 6/20, Loss: 0.0805, Accuracy: 0.9769\nValidation Accuracy: 0.8377\nTraining - Epoch 7/20, Loss: 0.0715, Accuracy: 0.9789\nValidation Accuracy: 0.8377\nTraining - Epoch 8/20, Loss: 0.0677, Accuracy: 0.9770\nValidation Accuracy: 0.8377\nTraining - Epoch 9/20, Loss: 0.0712, Accuracy: 0.9784\nValidation Accuracy: 0.8308\nTraining - Epoch 10/20, Loss: 0.0588, Accuracy: 0.9817\nValidation Accuracy: 0.8403\nTraining - Epoch 11/20, Loss: 0.0640, Accuracy: 0.9814\nValidation Accuracy: 0.8428\nTraining - Epoch 12/20, Loss: 0.0652, Accuracy: 0.9800\nValidation Accuracy: 0.8440\nTraining - Epoch 13/20, Loss: 0.0625, Accuracy: 0.9824\nValidation Accuracy: 0.8396\nTraining - Epoch 14/20, Loss: 0.0473, Accuracy: 0.9858\nValidation Accuracy: 0.8459\nTraining - Epoch 15/20, Loss: 0.0537, Accuracy: 0.9833\nValidation Accuracy: 0.8384\nTraining - Epoch 16/20, Loss: 0.0599, Accuracy: 0.9819\nValidation Accuracy: 0.8440\nTraining - Epoch 17/20, Loss: 0.0529, Accuracy: 0.9849\nValidation Accuracy: 0.8428\nTraining - Epoch 18/20, Loss: 0.0545, Accuracy: 0.9829\nValidation Accuracy: 0.8434\nTraining - Epoch 19/20, Loss: 0.0553, Accuracy: 0.9836\nValidation Accuracy: 0.8415\nTraining - Epoch 20/20, Loss: 0.0570, Accuracy: 0.9813\nValidation Accuracy: 0.8428\n","output_type":"stream"}]},{"cell_type":"code","source":"ids, predictions = evaluate_model_on_test_set(model, test_loader, device, class_mapping)\nrenamed_ids = list(range(len(ids)))\nresults = pd.DataFrame({\n    'ID': renamed_ids, \n    'TARGET': predictions \n})\n\nresults.to_csv('submission6.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T07:03:52.480906Z","iopub.execute_input":"2024-09-22T07:03:52.481705Z","iopub.status.idle":"2024-09-22T07:03:58.914076Z","shell.execute_reply.started":"2024-09-22T07:03:52.481668Z","shell.execute_reply":"2024-09-22T07:03:58.913162Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"results","metadata":{"execution":{"iopub.status.busy":"2024-09-22T07:04:09.824542Z","iopub.execute_input":"2024-09-22T07:04:09.824896Z","iopub.status.idle":"2024-09-22T07:04:09.836367Z","shell.execute_reply.started":"2024-09-22T07:04:09.824862Z","shell.execute_reply":"2024-09-22T07:04:09.835481Z"},"trusted":true},"execution_count":79,"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"        ID    TARGET\n0        0  class_58\n1        1  class_58\n2        2   class_7\n3        3  class_17\n4        4  class_71\n...    ...       ...\n1395  1395  class_69\n1396  1396  class_51\n1397  1397  class_56\n1398  1398  class_30\n1399  1399  class_55\n\n[1400 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>TARGET</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>class_58</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>class_58</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>class_7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>class_17</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>class_71</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1395</th>\n      <td>1395</td>\n      <td>class_69</td>\n    </tr>\n    <tr>\n      <th>1396</th>\n      <td>1396</td>\n      <td>class_51</td>\n    </tr>\n    <tr>\n      <th>1397</th>\n      <td>1397</td>\n      <td>class_56</td>\n    </tr>\n    <tr>\n      <th>1398</th>\n      <td>1398</td>\n      <td>class_30</td>\n    </tr>\n    <tr>\n      <th>1399</th>\n      <td>1399</td>\n      <td>class_55</td>\n    </tr>\n  </tbody>\n</table>\n<p>1400 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}