{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":85201,"databundleVersionId":9605463,"sourceType":"competition"}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This Python 3 environment comes with many helpful analytics libraries installed\nIt is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\nFor example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nInput data files are available in the read-only \"../input/\" directory\nFor example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nYou can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \nYou can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom PIL import Image\nfrom torch.utils.data import Dataset\nimport torch\nimport pandas as pd\nfrom torchvision import transforms\nfrom torch.utils.data import random_split, DataLoader\nimport torch.nn as nn\nimport torchvision.models as models\nimport torch.optim as optim","metadata":{"execution":{"iopub.status.busy":"2024-09-25T22:50:58.913923Z","iopub.execute_input":"2024-09-25T22:50:58.914244Z","iopub.status.idle":"2024-09-25T22:51:04.933111Z","shell.execute_reply.started":"2024-09-25T22:50:58.914210Z","shell.execute_reply":"2024-09-25T22:51:04.932127Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class ImageDataset(Dataset):\n    def __init__(self, csv_file, root_dir, transform=None, is_test=False):\n        self.data = pd.read_csv(csv_file)\n        self.root_dir = root_dir\n        self.transform = transform\n        self.is_test = is_test\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        if not self.is_test:\n            # Fetch training images using paths from train.csv\n            img_path = os.path.join(self.root_dir, self.data.iloc[idx, 1])\n            image = Image.open(img_path).convert('RGB')\n            label = int(self.data.iloc[idx, 0].split('_')[1]) - 1  # Labeling\n            label = torch.tensor(label)\n            if self.transform:\n                image = self.transform(image)\n            return image, label\n        else:\n            # For test data\n            img_path = os.path.join(self.root_dir, self.data.iloc[idx, 1])\n            image = Image.open(img_path).convert('RGB')\n            if self.transform:\n                image = self.transform(image)\n            return image, self.data.iloc[idx, 0]","metadata":{"execution":{"iopub.status.busy":"2024-09-25T22:51:11.963647Z","iopub.execute_input":"2024-09-25T22:51:11.964176Z","iopub.status.idle":"2024-09-25T22:51:11.974450Z","shell.execute_reply.started":"2024-09-25T22:51:11.964136Z","shell.execute_reply":"2024-09-25T22:51:11.973443Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Densenet169_ver5","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# Create datasets\ntrain_dataset = ImageDataset(\n    csv_file='/kaggle/input/dl-63-cw-image-classification/train.csv',  # Correct path to train.csv\n    root_dir='/kaggle/input/dl-63-cw-image-classification/train',  # Directory containing images\n    transform=transform\n)\n\ntest_dataset = ImageDataset(\n    csv_file='/kaggle/input/dl-63-cw-image-classification/test.csv',  # Correct path to test.csv\n    root_dir='/kaggle/input/dl-63-cw-image-classification/test/',  # Directory containing test images\n    transform=transform, is_test=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-25T22:51:15.140049Z","iopub.execute_input":"2024-09-25T22:51:15.140459Z","iopub.status.idle":"2024-09-25T22:51:15.178902Z","shell.execute_reply.started":"2024-09-25T22:51:15.140410Z","shell.execute_reply":"2024-09-25T22:51:15.178088Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_size = int(0.8 * len(train_dataset))\nvalid_size = len(train_dataset) - train_size\n\ntrainset, validset = random_split(train_dataset, [train_size, valid_size])\n\n# Create DataLoaders\nbatch_size = 32\ntrain_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(validset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T23:03:45.283798Z","iopub.execute_input":"2024-09-22T23:03:45.284246Z","iopub.status.idle":"2024-09-22T23:03:45.292243Z","shell.execute_reply.started":"2024-09-22T23:03:45.284209Z","shell.execute_reply":"2024-09-22T23:03:45.291092Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class CustomDenseNet169(nn.Module):\n    def __init__(self, num_classes=71):\n        super(CustomDenseNet169, self).__init__()\n        \n        # Load pre-trained DenseNet169 model\n        self.base_model = models.densenet169(pretrained=True)\n        \n        # Freeze earlier layers if needed (optional)\n        for param in self.base_model.features.parameters():\n            param.requires_grad = False\n        \n        # Replace the classifier layer with a new fully connected layer\n        self.base_model.classifier = nn.Sequential(\n            nn.Linear(self.base_model.classifier.in_features, 256),  # in_features based on DenseNet architecture\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(256, num_classes)  # Final output layer with num_classes outputs\n        )\n\n    def forward(self, x):\n        return self.base_model(x)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T23:05:12.972292Z","iopub.execute_input":"2024-09-22T23:05:12.973230Z","iopub.status.idle":"2024-09-22T23:05:12.980188Z","shell.execute_reply.started":"2024-09-22T23:05:12.973190Z","shell.execute_reply":"2024-09-22T23:05:12.979166Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = CustomDenseNet169(num_classes=71).to(device)\n\noptimizer = optim.RMSprop(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-09-22T23:05:34.335561Z","iopub.execute_input":"2024-09-22T23:05:34.336458Z","iopub.status.idle":"2024-09-22T23:05:35.632029Z","shell.execute_reply.started":"2024-09-22T23:05:34.336418Z","shell.execute_reply":"2024-09-22T23:05:35.631233Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet169_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet169_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/densenet169-b2777c0a.pth\" to /root/.cache/torch/hub/checkpoints/densenet169-b2777c0a.pth\n100%|██████████| 54.7M/54.7M [00:00<00:00, 124MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"def train_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n    best_val_acc = 0.0\n    for epoch in range(num_epochs):\n        model.train()  # Set to training mode\n        running_loss, running_corrects = 0.0, 0\n\n        # Training loop\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            _, preds = torch.max(outputs, 1)\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n\n        epoch_loss = running_loss / len(train_loader.dataset)\n        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n        print(f'Training - Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n\n        # Validation loop\n        model.eval()  # Set to evaluation mode\n        val_corrects = 0\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                _, preds = torch.max(outputs, 1)\n                val_corrects += torch.sum(preds == labels.data)\n\n        val_acc = val_corrects.double() / len(val_loader.dataset)\n        print(f'Validation Accuracy: {val_acc:.4f}')\n\n        # Save the best model based on validation accuracy\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), 'best_model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-09-22T23:05:56.505035Z","iopub.execute_input":"2024-09-22T23:05:56.505789Z","iopub.status.idle":"2024-09-22T23:05:56.517023Z","shell.execute_reply.started":"2024-09-22T23:05:56.505747Z","shell.execute_reply":"2024-09-22T23:05:56.515968Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=15)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T23:06:40.527299Z","iopub.execute_input":"2024-09-22T23:06:40.528022Z","iopub.status.idle":"2024-09-22T23:19:11.333771Z","shell.execute_reply.started":"2024-09-22T23:06:40.527979Z","shell.execute_reply":"2024-09-22T23:19:11.332745Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Training - Epoch 1/15, Loss: 2.2989, Accuracy: 0.4177\nValidation Accuracy: 0.8358\nTraining - Epoch 2/15, Loss: 1.0369, Accuracy: 0.6995\nValidation Accuracy: 0.8805\nTraining - Epoch 3/15, Loss: 0.7770, Accuracy: 0.7642\nValidation Accuracy: 0.8931\nTraining - Epoch 4/15, Loss: 0.6390, Accuracy: 0.8005\nValidation Accuracy: 0.9013\nTraining - Epoch 5/15, Loss: 0.5817, Accuracy: 0.8148\nValidation Accuracy: 0.9019\nTraining - Epoch 6/15, Loss: 0.5174, Accuracy: 0.8397\nValidation Accuracy: 0.9019\nTraining - Epoch 7/15, Loss: 0.4823, Accuracy: 0.8455\nValidation Accuracy: 0.9063\nTraining - Epoch 8/15, Loss: 0.4511, Accuracy: 0.8598\nValidation Accuracy: 0.9025\nTraining - Epoch 9/15, Loss: 0.4275, Accuracy: 0.8642\nValidation Accuracy: 0.8906\nTraining - Epoch 10/15, Loss: 0.4063, Accuracy: 0.8683\nValidation Accuracy: 0.9075\nTraining - Epoch 11/15, Loss: 0.3789, Accuracy: 0.8767\nValidation Accuracy: 0.9013\nTraining - Epoch 12/15, Loss: 0.3632, Accuracy: 0.8814\nValidation Accuracy: 0.9214\nTraining - Epoch 13/15, Loss: 0.3426, Accuracy: 0.8867\nValidation Accuracy: 0.9069\nTraining - Epoch 14/15, Loss: 0.3315, Accuracy: 0.8848\nValidation Accuracy: 0.9113\nTraining - Epoch 15/15, Loss: 0.3258, Accuracy: 0.8886\nValidation Accuracy: 0.9094\n","output_type":"stream"}]},{"cell_type":"code","source":"for param in model.base_model.features[:6].parameters():\n    param.requires_grad = False\n\n# Re-define optimizer for fine-tuning\noptimizer = optim.SGD(model.parameters(), lr=0.001)\n\n# Fine-tune the model\ntrain_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=15)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T23:21:35.836597Z","iopub.execute_input":"2024-09-22T23:21:35.837438Z","iopub.status.idle":"2024-09-22T23:33:39.648077Z","shell.execute_reply.started":"2024-09-22T23:21:35.837394Z","shell.execute_reply":"2024-09-22T23:33:39.646964Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Training - Epoch 1/15, Loss: 0.3054, Accuracy: 0.8980\nValidation Accuracy: 0.9126\nTraining - Epoch 2/15, Loss: 0.2657, Accuracy: 0.9119\nValidation Accuracy: 0.9157\nTraining - Epoch 3/15, Loss: 0.2724, Accuracy: 0.9078\nValidation Accuracy: 0.9138\nTraining - Epoch 4/15, Loss: 0.2582, Accuracy: 0.9183\nValidation Accuracy: 0.9176\nTraining - Epoch 5/15, Loss: 0.2588, Accuracy: 0.9155\nValidation Accuracy: 0.9189\nTraining - Epoch 6/15, Loss: 0.2509, Accuracy: 0.9149\nValidation Accuracy: 0.9176\nTraining - Epoch 7/15, Loss: 0.2447, Accuracy: 0.9213\nValidation Accuracy: 0.9151\nTraining - Epoch 8/15, Loss: 0.2411, Accuracy: 0.9228\nValidation Accuracy: 0.9145\nTraining - Epoch 9/15, Loss: 0.2484, Accuracy: 0.9150\nValidation Accuracy: 0.9164\nTraining - Epoch 10/15, Loss: 0.2371, Accuracy: 0.9235\nValidation Accuracy: 0.9170\nTraining - Epoch 11/15, Loss: 0.2457, Accuracy: 0.9202\nValidation Accuracy: 0.9157\nTraining - Epoch 12/15, Loss: 0.2396, Accuracy: 0.9199\nValidation Accuracy: 0.9201\nTraining - Epoch 13/15, Loss: 0.2327, Accuracy: 0.9237\nValidation Accuracy: 0.9214\nTraining - Epoch 14/15, Loss: 0.2369, Accuracy: 0.9245\nValidation Accuracy: 0.9226\nTraining - Epoch 15/15, Loss: 0.2371, Accuracy: 0.9237\nValidation Accuracy: 0.9138\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate_model_on_test_set(model, test_loader, device, class_mapping):\n    model.eval()\n    predictions = []\n    ids = []\n    \n    with torch.no_grad():\n        for images, image_ids in test_loader:\n            images = images.to(device)\n            outputs = model(images)\n            _, predicted_classes = torch.max(outputs, 1)\n            \n            predicted_classes = [class_mapping[p.item()] for p in predicted_classes]\n            \n        \n            predictions.extend(predicted_classes)\n            ids.extend(image_ids)  # image_ids chính là các ID từ file test.csv\n    \n    return ids, predictions\n\nclass_mapping = {i: f'class_{i+1}' for i in range(71)}","metadata":{"execution":{"iopub.status.busy":"2024-09-22T23:35:15.409052Z","iopub.execute_input":"2024-09-22T23:35:15.409484Z","iopub.status.idle":"2024-09-22T23:35:15.417582Z","shell.execute_reply.started":"2024-09-22T23:35:15.409446Z","shell.execute_reply":"2024-09-22T23:35:15.416398Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"ids, predictions = evaluate_model_on_test_set(model, test_loader, device, class_mapping)\nrenamed_ids = list(range(len(ids)))\nresults = pd.DataFrame({\n    'ID': renamed_ids, \n    'TARGET': predictions \n})\n\nresults.to_csv('submission9.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T23:35:26.283156Z","iopub.execute_input":"2024-09-22T23:35:26.283789Z","iopub.status.idle":"2024-09-22T23:35:42.170765Z","shell.execute_reply.started":"2024-09-22T23:35:26.283747Z","shell.execute_reply":"2024-09-22T23:35:42.169852Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# VER 6","metadata":{}},{"cell_type":"code","source":"train_size = int(0.8 * len(train_dataset))\nvalid_size = len(train_dataset) - train_size\ntrainset, validset = random_split(train_dataset, [train_size, valid_size])\n\nbatch_size = 64\ntrain_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(validset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T13:45:22.886270Z","iopub.execute_input":"2024-09-23T13:45:22.886665Z","iopub.status.idle":"2024-09-23T13:45:22.920852Z","shell.execute_reply.started":"2024-09-23T13:45:22.886628Z","shell.execute_reply":"2024-09-23T13:45:22.919856Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class CustomDenseNet169(nn.Module):\n    def __init__(self, num_classes=71):\n        super(CustomDenseNet169, self).__init__()\n        \n        # Load pre-trained DenseNet169 model\n        self.base_model = models.densenet169(pretrained=True)\n        \n        # Freeze earlier layers if needed (optional)\n        for param in self.base_model.features.parameters():\n            param.requires_grad = False\n        \n        # Replace the classifier layer with a new fully connected layer\n        self.base_model.classifier = nn.Sequential(\n            nn.Linear(self.base_model.classifier.in_features, 256),  # in_features based on DenseNet architecture\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(256, num_classes)  # Final output layer with num_classes outputs\n        )\n\n    def forward(self, x):\n        return self.base_model(x)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T13:45:29.902094Z","iopub.execute_input":"2024-09-23T13:45:29.902727Z","iopub.status.idle":"2024-09-23T13:45:29.909514Z","shell.execute_reply.started":"2024-09-23T13:45:29.902688Z","shell.execute_reply":"2024-09-23T13:45:29.908555Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = CustomDenseNet169(num_classes=71).to(device)\n\noptimizer = optim.RMSprop(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-09-23T13:45:46.718735Z","iopub.execute_input":"2024-09-23T13:45:46.719088Z","iopub.status.idle":"2024-09-23T13:45:47.764435Z","shell.execute_reply.started":"2024-09-23T13:45:46.719055Z","shell.execute_reply":"2024-09-23T13:45:47.763607Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet169_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet169_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/densenet169-b2777c0a.pth\" to /root/.cache/torch/hub/checkpoints/densenet169-b2777c0a.pth\n100%|██████████| 54.7M/54.7M [00:00<00:00, 183MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n    best_val_acc = 0.0\n    for epoch in range(num_epochs):\n        model.train()  # Set to training mode\n        running_loss, running_corrects = 0.0, 0\n\n        # Training loop\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            _, preds = torch.max(outputs, 1)\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n\n        epoch_loss = running_loss / len(train_loader.dataset)\n        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n        print(f'Training - Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n\n        # Validation loop\n        model.eval()  # Set to evaluation mode\n        val_corrects = 0\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                _, preds = torch.max(outputs, 1)\n                val_corrects += torch.sum(preds == labels.data)\n\n        val_acc = val_corrects.double() / len(val_loader.dataset)\n        print(f'Validation Accuracy: {val_acc:.4f}')\n\n        # Save the best model based on validation accuracy\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), 'best_model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-09-23T13:46:07.334803Z","iopub.execute_input":"2024-09-23T13:46:07.335519Z","iopub.status.idle":"2024-09-23T13:46:07.345925Z","shell.execute_reply.started":"2024-09-23T13:46:07.335469Z","shell.execute_reply":"2024-09-23T13:46:07.344979Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T13:46:29.932558Z","iopub.execute_input":"2024-09-23T13:46:29.933327Z","iopub.status.idle":"2024-09-23T13:52:27.258140Z","shell.execute_reply.started":"2024-09-23T13:46:29.933288Z","shell.execute_reply":"2024-09-23T13:52:27.257142Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Training - Epoch 1/10, Loss: 2.3712, Accuracy: 0.4273\nValidation Accuracy: 0.7862\nTraining - Epoch 2/10, Loss: 0.9902, Accuracy: 0.7196\nValidation Accuracy: 0.8629\nTraining - Epoch 3/10, Loss: 0.7304, Accuracy: 0.7885\nValidation Accuracy: 0.8899\nTraining - Epoch 4/10, Loss: 0.5983, Accuracy: 0.8255\nValidation Accuracy: 0.8805\nTraining - Epoch 5/10, Loss: 0.5230, Accuracy: 0.8435\nValidation Accuracy: 0.8912\nTraining - Epoch 6/10, Loss: 0.4571, Accuracy: 0.8576\nValidation Accuracy: 0.9069\nTraining - Epoch 7/10, Loss: 0.4357, Accuracy: 0.8617\nValidation Accuracy: 0.9019\nTraining - Epoch 8/10, Loss: 0.3962, Accuracy: 0.8757\nValidation Accuracy: 0.9013\nTraining - Epoch 9/10, Loss: 0.3828, Accuracy: 0.8826\nValidation Accuracy: 0.9094\nTraining - Epoch 10/10, Loss: 0.3453, Accuracy: 0.8888\nValidation Accuracy: 0.9063\n","output_type":"stream"}]},{"cell_type":"code","source":"for param in model.base_model.features[:6].parameters():\n    param.requires_grad = False\n\n# Re-define optimizer for fine-tuning\noptimizer = optim.SGD(model.parameters(), lr=0.001)\n\n# Fine-tune the model\ntrain_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=15)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T13:53:02.375889Z","iopub.execute_input":"2024-09-23T13:53:02.376279Z","iopub.status.idle":"2024-09-23T14:01:17.306987Z","shell.execute_reply.started":"2024-09-23T13:53:02.376241Z","shell.execute_reply":"2024-09-23T14:01:17.306041Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Training - Epoch 1/15, Loss: 0.3383, Accuracy: 0.8921\nValidation Accuracy: 0.9101\nTraining - Epoch 2/15, Loss: 0.3280, Accuracy: 0.8993\nValidation Accuracy: 0.9201\nTraining - Epoch 3/15, Loss: 0.3140, Accuracy: 0.8998\nValidation Accuracy: 0.9157\nTraining - Epoch 4/15, Loss: 0.3021, Accuracy: 0.9061\nValidation Accuracy: 0.9176\nTraining - Epoch 5/15, Loss: 0.2972, Accuracy: 0.9084\nValidation Accuracy: 0.9220\nTraining - Epoch 6/15, Loss: 0.2949, Accuracy: 0.9124\nValidation Accuracy: 0.9233\nTraining - Epoch 7/15, Loss: 0.2946, Accuracy: 0.9092\nValidation Accuracy: 0.9208\nTraining - Epoch 8/15, Loss: 0.2957, Accuracy: 0.9138\nValidation Accuracy: 0.9189\nTraining - Epoch 9/15, Loss: 0.2842, Accuracy: 0.9138\nValidation Accuracy: 0.9220\nTraining - Epoch 10/15, Loss: 0.2999, Accuracy: 0.9097\nValidation Accuracy: 0.9233\nTraining - Epoch 11/15, Loss: 0.2858, Accuracy: 0.9144\nValidation Accuracy: 0.9214\nTraining - Epoch 12/15, Loss: 0.2844, Accuracy: 0.9157\nValidation Accuracy: 0.9226\nTraining - Epoch 13/15, Loss: 0.2882, Accuracy: 0.9095\nValidation Accuracy: 0.9189\nTraining - Epoch 14/15, Loss: 0.2852, Accuracy: 0.9102\nValidation Accuracy: 0.9195\nTraining - Epoch 15/15, Loss: 0.2771, Accuracy: 0.9158\nValidation Accuracy: 0.9220\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate_model_on_test_set(model, test_loader, device, class_mapping):\n    model.eval()\n    predictions = []\n    ids = []\n    \n    with torch.no_grad():\n        for images, image_ids in test_loader:\n            images = images.to(device)\n            outputs = model(images)\n            _, predicted_classes = torch.max(outputs, 1)\n            \n            predicted_classes = [class_mapping[p.item()] for p in predicted_classes]\n            \n        \n            predictions.extend(predicted_classes)\n            ids.extend(image_ids)  # image_ids chính là các ID từ file test.csv\n    \n    return ids, predictions\n\nclass_mapping = {i: f'class_{i+1}' for i in range(71)}","metadata":{"execution":{"iopub.status.busy":"2024-09-23T14:01:29.161219Z","iopub.execute_input":"2024-09-23T14:01:29.162141Z","iopub.status.idle":"2024-09-23T14:01:29.169460Z","shell.execute_reply.started":"2024-09-23T14:01:29.162097Z","shell.execute_reply":"2024-09-23T14:01:29.168383Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"ids, predictions = evaluate_model_on_test_set(model, test_loader, device, class_mapping)\nrenamed_ids = list(range(len(ids)))\nresults = pd.DataFrame({\n    'ID': renamed_ids, \n    'TARGET': predictions \n})\n\nresults.to_csv('submission10.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T14:01:32.250813Z","iopub.execute_input":"2024-09-23T14:01:32.251203Z","iopub.status.idle":"2024-09-23T14:01:45.084257Z","shell.execute_reply.started":"2024-09-23T14:01:32.251167Z","shell.execute_reply":"2024-09-23T14:01:45.083231Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Ver 7","metadata":{}},{"cell_type":"code","source":"train_size = int(0.8 * len(train_dataset))\nvalid_size = len(train_dataset) - train_size\ntrainset, validset = random_split(train_dataset, [train_size, valid_size])\n\nbatch_size = 32\ntrain_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(validset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T14:13:15.236037Z","iopub.execute_input":"2024-09-23T14:13:15.236966Z","iopub.status.idle":"2024-09-23T14:13:15.243455Z","shell.execute_reply.started":"2024-09-23T14:13:15.236924Z","shell.execute_reply":"2024-09-23T14:13:15.242544Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class CustomDenseNet169(nn.Module):\n    def __init__(self, num_classes=71):\n        super(CustomDenseNet169, self).__init__()\n        \n        # Load pre-trained DenseNet169 model\n        self.base_model = models.densenet169(pretrained=True)\n        \n        # Freeze earlier layers if needed (optional)\n        for param in self.base_model.features.parameters():\n            param.requires_grad = False\n        \n        # Replace the classifier layer with a new fully connected layer\n        self.base_model.classifier = nn.Sequential(\n            nn.Linear(self.base_model.classifier.in_features, 256),  # in_features based on DenseNet architecture\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(256, num_classes)  # Final output layer with num_classes outputs\n        )\n\n    def forward(self, x):\n        return self.base_model(x)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T14:13:18.204738Z","iopub.execute_input":"2024-09-23T14:13:18.205511Z","iopub.status.idle":"2024-09-23T14:13:18.212447Z","shell.execute_reply.started":"2024-09-23T14:13:18.205460Z","shell.execute_reply":"2024-09-23T14:13:18.211423Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = CustomDenseNet169(num_classes=71).to(device)\n\noptimizer = optim.RMSprop(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-09-23T14:13:22.926060Z","iopub.execute_input":"2024-09-23T14:13:22.926936Z","iopub.status.idle":"2024-09-23T14:13:23.342435Z","shell.execute_reply.started":"2024-09-23T14:13:22.926894Z","shell.execute_reply":"2024-09-23T14:13:23.341462Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def train_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n    best_val_acc = 0.0\n    for epoch in range(num_epochs):\n        model.train()  # Set to training mode\n        running_loss, running_corrects = 0.0, 0\n\n        # Training loop\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            _, preds = torch.max(outputs, 1)\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n\n        epoch_loss = running_loss / len(train_loader.dataset)\n        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n        print(f'Training - Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n\n        # Validation loop\n        model.eval()  # Set to evaluation mode\n        val_corrects = 0\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                _, preds = torch.max(outputs, 1)\n                val_corrects += torch.sum(preds == labels.data)\n\n        val_acc = val_corrects.double() / len(val_loader.dataset)\n        print(f'Validation Accuracy: {val_acc:.4f}')\n\n        # Save the best model based on validation accuracy\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), 'best_model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-09-23T14:13:25.650315Z","iopub.execute_input":"2024-09-23T14:13:25.650946Z","iopub.status.idle":"2024-09-23T14:13:25.662611Z","shell.execute_reply.started":"2024-09-23T14:13:25.650904Z","shell.execute_reply":"2024-09-23T14:13:25.661730Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T14:13:35.408790Z","iopub.execute_input":"2024-09-23T14:13:35.409181Z","iopub.status.idle":"2024-09-23T14:19:11.826699Z","shell.execute_reply.started":"2024-09-23T14:13:35.409142Z","shell.execute_reply":"2024-09-23T14:19:11.825682Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Training - Epoch 1/10, Loss: 2.2903, Accuracy: 0.4292\nValidation Accuracy: 0.8711\nTraining - Epoch 2/10, Loss: 0.9901, Accuracy: 0.7177\nValidation Accuracy: 0.8774\nTraining - Epoch 3/10, Loss: 0.7434, Accuracy: 0.7703\nValidation Accuracy: 0.9050\nTraining - Epoch 4/10, Loss: 0.6308, Accuracy: 0.8043\nValidation Accuracy: 0.9069\nTraining - Epoch 5/10, Loss: 0.5644, Accuracy: 0.8271\nValidation Accuracy: 0.9088\nTraining - Epoch 6/10, Loss: 0.5133, Accuracy: 0.8376\nValidation Accuracy: 0.9050\nTraining - Epoch 7/10, Loss: 0.4732, Accuracy: 0.8463\nValidation Accuracy: 0.9088\nTraining - Epoch 8/10, Loss: 0.4468, Accuracy: 0.8513\nValidation Accuracy: 0.9220\nTraining - Epoch 9/10, Loss: 0.4245, Accuracy: 0.8611\nValidation Accuracy: 0.9151\nTraining - Epoch 10/10, Loss: 0.4086, Accuracy: 0.8638\nValidation Accuracy: 0.9132\n","output_type":"stream"}]},{"cell_type":"code","source":"# for param in model.base_model.features[:6].parameters():\n#     param.requires_grad = False\n\nfor param in model.base_model.features[:2].parameters():\n    param.requires_grad = False\n    \n# Re-define optimizer for fine-tuning\noptimizer = optim.SGD(model.parameters(), lr=0.001)\n\n# Fine-tune the model\ntrain_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=15)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T14:20:38.714567Z","iopub.execute_input":"2024-09-23T14:20:38.714959Z","iopub.status.idle":"2024-09-23T14:28:55.970151Z","shell.execute_reply.started":"2024-09-23T14:20:38.714922Z","shell.execute_reply":"2024-09-23T14:28:55.969185Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Training - Epoch 1/15, Loss: 0.3933, Accuracy: 0.8685\nValidation Accuracy: 0.9182\nTraining - Epoch 2/15, Loss: 0.3630, Accuracy: 0.8829\nValidation Accuracy: 0.9189\nTraining - Epoch 3/15, Loss: 0.3380, Accuracy: 0.8889\nValidation Accuracy: 0.9220\nTraining - Epoch 4/15, Loss: 0.3302, Accuracy: 0.8992\nValidation Accuracy: 0.9208\nTraining - Epoch 5/15, Loss: 0.3412, Accuracy: 0.8921\nValidation Accuracy: 0.9208\nTraining - Epoch 6/15, Loss: 0.3131, Accuracy: 0.8985\nValidation Accuracy: 0.9214\nTraining - Epoch 7/15, Loss: 0.3100, Accuracy: 0.8985\nValidation Accuracy: 0.9226\nTraining - Epoch 8/15, Loss: 0.3110, Accuracy: 0.8993\nValidation Accuracy: 0.9189\nTraining - Epoch 9/15, Loss: 0.3183, Accuracy: 0.8984\nValidation Accuracy: 0.9214\nTraining - Epoch 10/15, Loss: 0.3089, Accuracy: 0.8984\nValidation Accuracy: 0.9220\nTraining - Epoch 11/15, Loss: 0.3176, Accuracy: 0.8990\nValidation Accuracy: 0.9164\nTraining - Epoch 12/15, Loss: 0.3183, Accuracy: 0.8957\nValidation Accuracy: 0.9233\nTraining - Epoch 13/15, Loss: 0.3185, Accuracy: 0.9012\nValidation Accuracy: 0.9258\nTraining - Epoch 14/15, Loss: 0.3127, Accuracy: 0.9010\nValidation Accuracy: 0.9201\nTraining - Epoch 15/15, Loss: 0.3053, Accuracy: 0.9045\nValidation Accuracy: 0.9252\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate_model_on_test_set(model, test_loader, device, class_mapping):\n    model.eval()\n    predictions = []\n    ids = []\n    \n    with torch.no_grad():\n        for images, image_ids in test_loader:\n            images = images.to(device)\n            outputs = model(images)\n            _, predicted_classes = torch.max(outputs, 1)\n            \n            predicted_classes = [class_mapping[p.item()] for p in predicted_classes]\n            \n        \n            predictions.extend(predicted_classes)\n            ids.extend(image_ids)  # image_ids chính là các ID từ file test.csv\n    \n    return ids, predictions\n\nclass_mapping = {i: f'class_{i+1}' for i in range(71)}","metadata":{"execution":{"iopub.status.busy":"2024-09-23T14:29:31.215573Z","iopub.execute_input":"2024-09-23T14:29:31.216701Z","iopub.status.idle":"2024-09-23T14:29:31.224428Z","shell.execute_reply.started":"2024-09-23T14:29:31.216646Z","shell.execute_reply":"2024-09-23T14:29:31.223451Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"ids, predictions = evaluate_model_on_test_set(model, test_loader, device, class_mapping)\nrenamed_ids = list(range(len(ids)))\nresults = pd.DataFrame({\n    'ID': renamed_ids, \n    'TARGET': predictions \n})\n\nresults.to_csv('submission11.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T14:29:33.707859Z","iopub.execute_input":"2024-09-23T14:29:33.708494Z","iopub.status.idle":"2024-09-23T14:29:40.611177Z","shell.execute_reply.started":"2024-09-23T14:29:33.708443Z","shell.execute_reply":"2024-09-23T14:29:40.610172Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Densenet201","metadata":{}},{"cell_type":"markdown","source":"# Ver 8","metadata":{}},{"cell_type":"code","source":"train_size = int(0.8 * len(train_dataset))\nvalid_size = len(train_dataset) - train_size\ntrainset, validset = random_split(train_dataset, [train_size, valid_size])\n\nbatch_size = 64\ntrain_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(validset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T14:53:11.724652Z","iopub.execute_input":"2024-09-23T14:53:11.725050Z","iopub.status.idle":"2024-09-23T14:53:11.731829Z","shell.execute_reply.started":"2024-09-23T14:53:11.725011Z","shell.execute_reply":"2024-09-23T14:53:11.730941Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"class CustomDenseNet201(nn.Module):\n    def __init__(self, num_classes=71):\n        super(CustomDenseNet201, self).__init__()\n        \n        # Load pre-trained DenseNet201 model\n        self.base_model = models.densenet201(pretrained=True)\n        \n        # Freeze earlier layers (feature extraction layers)\n        for param in self.base_model.features.parameters():\n            param.requires_grad = False  # Freeze all feature extraction layers\n\n        # Replace the classifier layer with a new fully connected layer\n        self.base_model.classifier = nn.Sequential(\n            nn.Linear(self.base_model.classifier.in_features, 256),  # in_features based on DenseNet architecture\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(256, num_classes)  # Final output layer with num_classes outputs\n        )\n\n    def forward(self, x):\n        return self.base_model(x)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T14:53:14.070042Z","iopub.execute_input":"2024-09-23T14:53:14.070416Z","iopub.status.idle":"2024-09-23T14:53:14.077578Z","shell.execute_reply.started":"2024-09-23T14:53:14.070379Z","shell.execute_reply":"2024-09-23T14:53:14.076557Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = CustomDenseNet201(num_classes=71).to(device)\noptimizer = optim.RMSprop(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-09-23T14:53:17.490121Z","iopub.execute_input":"2024-09-23T14:53:17.490511Z","iopub.status.idle":"2024-09-23T14:53:18.039062Z","shell.execute_reply.started":"2024-09-23T14:53:17.490454Z","shell.execute_reply":"2024-09-23T14:53:18.038034Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def train_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n    best_val_acc = 0.0\n    for epoch in range(num_epochs):\n        model.train()  # Set to training mode\n        running_loss, running_corrects = 0.0, 0\n\n        # Training loop\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            _, preds = torch.max(outputs, 1)\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n\n        epoch_loss = running_loss / len(train_loader.dataset)\n        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n        print(f'Training - Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n\n        # Validation loop\n        model.eval()  # Set to evaluation mode\n        val_corrects = 0\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                _, preds = torch.max(outputs, 1)\n                val_corrects += torch.sum(preds == labels.data)\n\n        val_acc = val_corrects.double() / len(val_loader.dataset)\n        print(f'Validation Accuracy: {val_acc:.4f}')\n\n        # Save the best model based on validation accuracy\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), 'best_model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-09-23T14:53:22.340754Z","iopub.execute_input":"2024-09-23T14:53:22.341149Z","iopub.status.idle":"2024-09-23T14:53:22.351786Z","shell.execute_reply.started":"2024-09-23T14:53:22.341104Z","shell.execute_reply":"2024-09-23T14:53:22.350851Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T14:53:25.142129Z","iopub.execute_input":"2024-09-23T14:53:25.142514Z","iopub.status.idle":"2024-09-23T14:59:22.993330Z","shell.execute_reply.started":"2024-09-23T14:53:25.142464Z","shell.execute_reply":"2024-09-23T14:59:22.992203Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Training - Epoch 1/10, Loss: 2.3120, Accuracy: 0.4309\nValidation Accuracy: 0.8409\nTraining - Epoch 2/10, Loss: 0.9820, Accuracy: 0.7280\nValidation Accuracy: 0.8730\nTraining - Epoch 3/10, Loss: 0.7057, Accuracy: 0.7937\nValidation Accuracy: 0.8943\nTraining - Epoch 4/10, Loss: 0.5914, Accuracy: 0.8244\nValidation Accuracy: 0.8987\nTraining - Epoch 5/10, Loss: 0.5094, Accuracy: 0.8441\nValidation Accuracy: 0.9069\nTraining - Epoch 6/10, Loss: 0.4564, Accuracy: 0.8615\nValidation Accuracy: 0.8962\nTraining - Epoch 7/10, Loss: 0.4188, Accuracy: 0.8688\nValidation Accuracy: 0.9050\nTraining - Epoch 8/10, Loss: 0.3817, Accuracy: 0.8784\nValidation Accuracy: 0.8956\nTraining - Epoch 9/10, Loss: 0.3542, Accuracy: 0.8888\nValidation Accuracy: 0.9044\nTraining - Epoch 10/10, Loss: 0.3197, Accuracy: 0.8957\nValidation Accuracy: 0.9132\n","output_type":"stream"}]},{"cell_type":"code","source":"for param in model.base_model.features[:2].parameters():\n    param.requires_grad = False\n    \n# Re-define optimizer for fine-tuning\noptimizer = optim.SGD(model.parameters(), lr=0.001)\n\n# Fine-tune the model\ntrain_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=15)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T14:59:47.971612Z","iopub.execute_input":"2024-09-23T14:59:47.972007Z","iopub.status.idle":"2024-09-23T15:08:38.897111Z","shell.execute_reply.started":"2024-09-23T14:59:47.971966Z","shell.execute_reply":"2024-09-23T15:08:38.896125Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Training - Epoch 1/15, Loss: 0.3367, Accuracy: 0.8910\nValidation Accuracy: 0.9151\nTraining - Epoch 2/15, Loss: 0.3045, Accuracy: 0.9031\nValidation Accuracy: 0.9220\nTraining - Epoch 3/15, Loss: 0.3008, Accuracy: 0.9073\nValidation Accuracy: 0.9233\nTraining - Epoch 4/15, Loss: 0.2943, Accuracy: 0.9095\nValidation Accuracy: 0.9220\nTraining - Epoch 5/15, Loss: 0.3033, Accuracy: 0.9042\nValidation Accuracy: 0.9233\nTraining - Epoch 6/15, Loss: 0.2960, Accuracy: 0.9091\nValidation Accuracy: 0.9220\nTraining - Epoch 7/15, Loss: 0.2816, Accuracy: 0.9146\nValidation Accuracy: 0.9220\nTraining - Epoch 8/15, Loss: 0.2785, Accuracy: 0.9122\nValidation Accuracy: 0.9201\nTraining - Epoch 9/15, Loss: 0.2690, Accuracy: 0.9143\nValidation Accuracy: 0.9220\nTraining - Epoch 10/15, Loss: 0.2721, Accuracy: 0.9177\nValidation Accuracy: 0.9182\nTraining - Epoch 11/15, Loss: 0.2735, Accuracy: 0.9157\nValidation Accuracy: 0.9189\nTraining - Epoch 12/15, Loss: 0.2751, Accuracy: 0.9150\nValidation Accuracy: 0.9176\nTraining - Epoch 13/15, Loss: 0.2741, Accuracy: 0.9138\nValidation Accuracy: 0.9214\nTraining - Epoch 14/15, Loss: 0.2677, Accuracy: 0.9157\nValidation Accuracy: 0.9195\nTraining - Epoch 15/15, Loss: 0.2722, Accuracy: 0.9157\nValidation Accuracy: 0.9220\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate_model_on_test_set(model, test_loader, device, class_mapping):\n    model.eval()\n    predictions = []\n    ids = []\n    \n    with torch.no_grad():\n        for images, image_ids in test_loader:\n            images = images.to(device)\n            outputs = model(images)\n            _, predicted_classes = torch.max(outputs, 1)\n            \n            predicted_classes = [class_mapping[p.item()] for p in predicted_classes]\n            \n        \n            predictions.extend(predicted_classes)\n            ids.extend(image_ids)  # image_ids chính là các ID từ file test.csv\n    \n    return ids, predictions\n\nclass_mapping = {i: f'class_{i+1}' for i in range(71)}","metadata":{"execution":{"iopub.status.busy":"2024-09-23T15:10:19.463285Z","iopub.execute_input":"2024-09-23T15:10:19.464054Z","iopub.status.idle":"2024-09-23T15:10:19.471343Z","shell.execute_reply.started":"2024-09-23T15:10:19.464012Z","shell.execute_reply":"2024-09-23T15:10:19.470332Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"ids, predictions = evaluate_model_on_test_set(model, test_loader, device, class_mapping)\nrenamed_ids = list(range(len(ids)))\nresults = pd.DataFrame({\n    'ID': renamed_ids, \n    'TARGET': predictions \n})\n\nresults.to_csv('submission12.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T15:10:22.246503Z","iopub.execute_input":"2024-09-23T15:10:22.247363Z","iopub.status.idle":"2024-09-23T15:10:29.981042Z","shell.execute_reply.started":"2024-09-23T15:10:22.247322Z","shell.execute_reply":"2024-09-23T15:10:29.980034Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# VER 8.1","metadata":{}},{"cell_type":"code","source":"train_size = int(0.8 * len(train_dataset))\nvalid_size = len(train_dataset) - train_size\ntrainset, validset = random_split(train_dataset, [train_size, valid_size])\n\nbatch_size = 64\ntrain_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(validset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-25T22:51:43.193368Z","iopub.execute_input":"2024-09-25T22:51:43.194258Z","iopub.status.idle":"2024-09-25T22:51:43.226716Z","shell.execute_reply.started":"2024-09-25T22:51:43.194217Z","shell.execute_reply":"2024-09-25T22:51:43.225942Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class CustomDenseNet201(nn.Module):\n    def __init__(self, num_classes=71):\n        super(CustomDenseNet201, self).__init__()\n        \n        # Load pre-trained DenseNet201 model\n        self.base_model = models.densenet201(pretrained=True)\n        \n        # Freeze earlier layers (feature extraction layers)\n        for param in self.base_model.features.parameters():\n            param.requires_grad = False  # Freeze all feature extraction layers\n\n        # Replace the classifier layer with a new fully connected layer\n        self.base_model.classifier = nn.Sequential(\n            nn.Linear(self.base_model.classifier.in_features, 256),  # in_features based on DenseNet architecture\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(256, num_classes)  # Final output layer with num_classes outputs\n        )\n\n    def forward(self, x):\n        return self.base_model(x)","metadata":{"execution":{"iopub.status.busy":"2024-09-25T22:52:33.739925Z","iopub.execute_input":"2024-09-25T22:52:33.740304Z","iopub.status.idle":"2024-09-25T22:52:33.747879Z","shell.execute_reply.started":"2024-09-25T22:52:33.740262Z","shell.execute_reply":"2024-09-25T22:52:33.746772Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = CustomDenseNet201(num_classes=71).to(device)\noptimizer = optim.RMSprop(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-09-25T22:52:37.543998Z","iopub.execute_input":"2024-09-25T22:52:37.544377Z","iopub.status.idle":"2024-09-25T22:52:38.956068Z","shell.execute_reply.started":"2024-09-25T22:52:37.544340Z","shell.execute_reply":"2024-09-25T22:52:38.955285Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet201_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet201_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/densenet201-c1103571.pth\" to /root/.cache/torch/hub/checkpoints/densenet201-c1103571.pth\n100%|██████████| 77.4M/77.4M [00:00<00:00, 192MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n    best_val_acc = 0.0\n    for epoch in range(num_epochs):\n        model.train()  # Set to training mode\n        running_loss, running_corrects = 0.0, 0\n\n        # Training loop\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            _, preds = torch.max(outputs, 1)\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n\n        epoch_loss = running_loss / len(train_loader.dataset)\n        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n        print(f'Training - Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n\n        # Validation loop\n        model.eval()  # Set to evaluation mode\n        val_corrects = 0\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                _, preds = torch.max(outputs, 1)\n                val_corrects += torch.sum(preds == labels.data)\n\n        val_acc = val_corrects.double() / len(val_loader.dataset)\n        print(f'Validation Accuracy: {val_acc:.4f}')\n\n        # Save the best model based on validation accuracy\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), 'best_model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-09-25T22:52:42.197248Z","iopub.execute_input":"2024-09-25T22:52:42.197780Z","iopub.status.idle":"2024-09-25T22:52:42.209624Z","shell.execute_reply.started":"2024-09-25T22:52:42.197727Z","shell.execute_reply":"2024-09-25T22:52:42.208535Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10)","metadata":{"execution":{"iopub.status.busy":"2024-09-25T22:53:01.183521Z","iopub.execute_input":"2024-09-25T22:53:01.184403Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Training - Epoch 1/10, Loss: 2.4028, Accuracy: 0.4097\nValidation Accuracy: 0.7994\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_and_val_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[7], line 11\u001b[0m, in \u001b[0;36mtrain_and_val_model\u001b[0;34m(model, criterion, optimizer, train_loader, val_loader, num_epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 11\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     13\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[5], line 21\u001b[0m, in \u001b[0;36mCustomDenseNet201.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/densenet.py:213\u001b[0m, in \u001b[0;36mDenseNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 213\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(features, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    215\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39madaptive_avg_pool2d(out, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/densenet.py:122\u001b[0m, in \u001b[0;36m_DenseBlock.forward\u001b[0;34m(self, init_features)\u001b[0m\n\u001b[1;32m    120\u001b[0m features \u001b[38;5;241m=\u001b[39m [init_features]\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 122\u001b[0m     new_features \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(new_features)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(features, \u001b[38;5;241m1\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/densenet.py:90\u001b[0m, in \u001b[0;36m_DenseLayer.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn_function(prev_features)\n\u001b[0;32m---> 90\u001b[0m new_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbottleneck_output\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_rate \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     92\u001b[0m     new_features \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(new_features, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_rate, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"for param in model.base_model.features[:0].parameters():\n    param.requires_grad = False\n    \n# Re-define optimizer for fine-tuning\noptimizer = optim.SGD(model.parameters(), lr=0.001)\n\n# Fine-tune the model\ntrain_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10)","metadata":{"execution":{"iopub.status.busy":"2024-09-25T10:43:09.802362Z","iopub.execute_input":"2024-09-25T10:43:09.803204Z","iopub.status.idle":"2024-09-25T10:53:36.080733Z","shell.execute_reply.started":"2024-09-25T10:43:09.803164Z","shell.execute_reply":"2024-09-25T10:53:36.079606Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Training - Epoch 1/10, Loss: 0.1999, Accuracy: 0.9342\nValidation Accuracy: 0.9352\nTraining - Epoch 2/10, Loss: 0.1737, Accuracy: 0.9449\nValidation Accuracy: 0.9377\nTraining - Epoch 3/10, Loss: 0.1644, Accuracy: 0.9427\nValidation Accuracy: 0.9377\nTraining - Epoch 4/10, Loss: 0.1613, Accuracy: 0.9520\nValidation Accuracy: 0.9371\nTraining - Epoch 5/10, Loss: 0.1581, Accuracy: 0.9470\nValidation Accuracy: 0.9346\nTraining - Epoch 6/10, Loss: 0.1570, Accuracy: 0.9508\nValidation Accuracy: 0.9390\nTraining - Epoch 7/10, Loss: 0.1591, Accuracy: 0.9498\nValidation Accuracy: 0.9352\nTraining - Epoch 8/10, Loss: 0.1496, Accuracy: 0.9512\nValidation Accuracy: 0.9365\nTraining - Epoch 9/10, Loss: 0.1504, Accuracy: 0.9542\nValidation Accuracy: 0.9390\nTraining - Epoch 10/10, Loss: 0.1466, Accuracy: 0.9520\nValidation Accuracy: 0.9340\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate_model_on_test_set(model, test_loader, device, class_mapping):\n    model.eval()\n    predictions = []\n    ids = []\n    \n    with torch.no_grad():\n        for images, image_ids in test_loader:\n            images = images.to(device)\n            outputs = model(images)\n            _, predicted_classes = torch.max(outputs, 1)\n            \n            predicted_classes = [class_mapping[p.item()] for p in predicted_classes]\n            \n        \n            predictions.extend(predicted_classes)\n            ids.extend(image_ids)  # image_ids chính là các ID từ file test.csv\n    \n    return ids, predictions\n\nclass_mapping = {i: f'class_{i+1}' for i in range(71)}","metadata":{"execution":{"iopub.status.busy":"2024-09-25T10:54:25.994704Z","iopub.execute_input":"2024-09-25T10:54:25.995097Z","iopub.status.idle":"2024-09-25T10:54:26.002209Z","shell.execute_reply.started":"2024-09-25T10:54:25.995060Z","shell.execute_reply":"2024-09-25T10:54:26.001297Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"ids, predictions = evaluate_model_on_test_set(model, test_loader, device, class_mapping)\nrenamed_ids = list(range(len(ids)))\nresults = pd.DataFrame({\n    'ID': renamed_ids, \n    'TARGET': predictions \n})\n\nresults.to_csv('submission18.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-25T10:54:30.331342Z","iopub.execute_input":"2024-09-25T10:54:30.331724Z","iopub.status.idle":"2024-09-25T10:54:56.703649Z","shell.execute_reply.started":"2024-09-25T10:54:30.331688Z","shell.execute_reply":"2024-09-25T10:54:56.702728Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Esemble","metadata":{}},{"cell_type":"code","source":"train_size = int(0.8 * len(train_dataset))\nvalid_size = len(train_dataset) - train_size\n\ntrainset, validset = random_split(train_dataset, [train_size, valid_size])\n\n# Create DataLoaders\nbatch_size = 64\ntrain_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(validset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T23:36:11.091474Z","iopub.execute_input":"2024-09-24T23:36:11.091858Z","iopub.status.idle":"2024-09-24T23:36:11.098474Z","shell.execute_reply.started":"2024-09-24T23:36:11.091822Z","shell.execute_reply":"2024-09-24T23:36:11.097577Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class CustomDenseNet201(nn.Module):\n    def __init__(self, num_classes=71):\n        super(CustomDenseNet201, self).__init__()\n        self.base_model = models.densenet201(pretrained=True)\n        \n        # Freeze earlier layers (optional, based on your strategy)\n        for param in self.base_model.features.parameters():\n            param.requires_grad = False\n        \n        # Modify the classifier\n        in_features = self.base_model.classifier.in_features\n        self.base_model.classifier = nn.Sequential(\n            nn.Linear(in_features, 512),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(512, num_classes)\n        )\n    \n    def forward(self, x):\n        return self.base_model(x)\n\nclass CustomResNet50(nn.Module):\n    def __init__(self, num_classes=71):\n        super(CustomResNet50, self).__init__()\n        self.base_model = models.resnet50(pretrained=True)\n        \n        # Freeze earlier layers (optional)\n        for param in self.base_model.parameters():\n            param.requires_grad = False\n        \n        # Modify the classifier\n        in_features = self.base_model.fc.in_features\n        self.base_model.fc = nn.Sequential(\n            nn.Linear(in_features, 512),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(512, num_classes)\n        )\n    \n    def forward(self, x):\n        return self.base_model(x)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T23:36:13.654183Z","iopub.execute_input":"2024-09-24T23:36:13.654599Z","iopub.status.idle":"2024-09-24T23:36:13.664930Z","shell.execute_reply.started":"2024-09-24T23:36:13.654562Z","shell.execute_reply":"2024-09-24T23:36:13.663927Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class EnsembleModel(nn.Module):\n    def __init__(self, num_classes=71):\n        super(EnsembleModel, self).__init__()\n        self.densenet = CustomDenseNet201(num_classes)\n        self.resnet = CustomResNet50(num_classes)\n        \n        # Combine outputs\n        self.fc = nn.Linear(num_classes * 2, num_classes)  # Combine predictions from both models\n    \n    def forward(self, x):\n        densenet_output = self.densenet(x)\n        resnet_output = self.resnet(x)\n        \n        # Concatenate outputs\n        combined_output = torch.cat((densenet_output, resnet_output), dim=1)\n        \n        # Pass through final classifier\n        final_output = self.fc(combined_output)\n        \n        return final_output","metadata":{"execution":{"iopub.status.busy":"2024-09-24T23:36:18.861356Z","iopub.execute_input":"2024-09-24T23:36:18.861745Z","iopub.status.idle":"2024-09-24T23:36:18.868453Z","shell.execute_reply.started":"2024-09-24T23:36:18.861709Z","shell.execute_reply":"2024-09-24T23:36:18.867547Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel = EnsembleModel(num_classes=71).to(device)\n\noptimizer = torch.optim.RMSprop(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-09-24T23:36:21.381442Z","iopub.execute_input":"2024-09-24T23:36:21.381788Z","iopub.status.idle":"2024-09-24T23:36:22.459519Z","shell.execute_reply.started":"2024-09-24T23:36:21.381756Z","shell.execute_reply":"2024-09-24T23:36:22.458509Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def train_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n    best_val_acc = 0.0\n    for epoch in range(num_epochs):\n        model.train()  # Set to training mode\n        running_loss, running_corrects = 0.0, 0\n\n        # Training loop\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            _, preds = torch.max(outputs, 1)\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n\n        epoch_loss = running_loss / len(train_loader.dataset)\n        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n        print(f'Training - Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n\n        # Validation loop\n        model.eval()  # Set to evaluation mode\n        val_corrects = 0\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                _, preds = torch.max(outputs, 1)\n                val_corrects += torch.sum(preds == labels.data)\n\n        val_acc = val_corrects.double() / len(val_loader.dataset)\n        print(f'Validation Accuracy: {val_acc:.4f}')\n\n        # Save the best model based on validation accuracy\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), 'best_model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-09-24T23:36:26.349721Z","iopub.execute_input":"2024-09-24T23:36:26.350094Z","iopub.status.idle":"2024-09-24T23:36:26.360850Z","shell.execute_reply.started":"2024-09-24T23:36:26.350058Z","shell.execute_reply":"2024-09-24T23:36:26.359807Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=15)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T23:36:32.307345Z","iopub.execute_input":"2024-09-24T23:36:32.307962Z","iopub.status.idle":"2024-09-24T23:48:21.246011Z","shell.execute_reply.started":"2024-09-24T23:36:32.307924Z","shell.execute_reply":"2024-09-24T23:48:21.245084Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Training - Epoch 1/15, Loss: 2.4865, Accuracy: 0.4456\nValidation Accuracy: 0.7717\nTraining - Epoch 2/15, Loss: 0.7420, Accuracy: 0.7865\nValidation Accuracy: 0.8453\nTraining - Epoch 3/15, Loss: 0.5494, Accuracy: 0.8295\nValidation Accuracy: 0.8302\nTraining - Epoch 4/15, Loss: 0.4692, Accuracy: 0.8491\nValidation Accuracy: 0.8987\nTraining - Epoch 5/15, Loss: 0.3985, Accuracy: 0.8727\nValidation Accuracy: 0.8855\nTraining - Epoch 6/15, Loss: 0.3613, Accuracy: 0.8787\nValidation Accuracy: 0.9013\nTraining - Epoch 7/15, Loss: 0.3348, Accuracy: 0.8933\nValidation Accuracy: 0.9000\nTraining - Epoch 8/15, Loss: 0.3076, Accuracy: 0.8988\nValidation Accuracy: 0.8931\nTraining - Epoch 9/15, Loss: 0.2839, Accuracy: 0.9039\nValidation Accuracy: 0.9025\nTraining - Epoch 10/15, Loss: 0.2721, Accuracy: 0.9083\nValidation Accuracy: 0.8931\nTraining - Epoch 11/15, Loss: 0.2517, Accuracy: 0.9179\nValidation Accuracy: 0.8950\nTraining - Epoch 12/15, Loss: 0.2382, Accuracy: 0.9198\nValidation Accuracy: 0.8673\nTraining - Epoch 13/15, Loss: 0.2300, Accuracy: 0.9232\nValidation Accuracy: 0.8962\nTraining - Epoch 14/15, Loss: 0.2153, Accuracy: 0.9262\nValidation Accuracy: 0.9157\nTraining - Epoch 15/15, Loss: 0.2038, Accuracy: 0.9303\nValidation Accuracy: 0.8704\n","output_type":"stream"}]},{"cell_type":"code","source":"for param in model.densenet.base_model.features[-2:].parameters():  # Unfreeze last 2 layers of DenseNet201\n    param.requires_grad = True\n\nfor param in model.resnet.base_model.layer4.parameters():  # Unfreeze layer 4 of ResNet50\n    param.requires_grad = True\n\n# Re-define optimizer for fine-tuning\noptimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001)\ntrain_and_val_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T23:54:27.531434Z","iopub.execute_input":"2024-09-24T23:54:27.532082Z","iopub.status.idle":"2024-09-25T00:03:26.730390Z","shell.execute_reply.started":"2024-09-24T23:54:27.532042Z","shell.execute_reply":"2024-09-25T00:03:26.729491Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Training - Epoch 1/10, Loss: 0.3837, Accuracy: 0.8767\nValidation Accuracy: 0.8818\nTraining - Epoch 2/10, Loss: 0.3500, Accuracy: 0.8881\nValidation Accuracy: 0.8780\nTraining - Epoch 3/10, Loss: 0.3370, Accuracy: 0.8903\nValidation Accuracy: 0.8899\nTraining - Epoch 4/10, Loss: 0.3245, Accuracy: 0.8944\nValidation Accuracy: 0.8937\nTraining - Epoch 5/10, Loss: 0.3146, Accuracy: 0.8995\nValidation Accuracy: 0.8950\nTraining - Epoch 6/10, Loss: 0.2776, Accuracy: 0.9073\nValidation Accuracy: 0.8994\nTraining - Epoch 7/10, Loss: 0.2821, Accuracy: 0.9051\nValidation Accuracy: 0.9057\nTraining - Epoch 8/10, Loss: 0.2754, Accuracy: 0.9108\nValidation Accuracy: 0.9044\nTraining - Epoch 9/10, Loss: 0.2569, Accuracy: 0.9163\nValidation Accuracy: 0.9038\nTraining - Epoch 10/10, Loss: 0.2500, Accuracy: 0.9176\nValidation Accuracy: 0.9031\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate_model_on_test_set(model, test_loader, device, class_mapping):\n    model.eval()\n    predictions = []\n    ids = []\n    \n    with torch.no_grad():\n        for images, image_ids in test_loader:\n            images = images.to(device)\n            outputs = model(images)\n            _, predicted_classes = torch.max(outputs, 1)\n            \n            predicted_classes = [class_mapping[p.item()] for p in predicted_classes]\n            \n        \n            predictions.extend(predicted_classes)\n            ids.extend(image_ids)  # image_ids chính là các ID từ file test.csv\n    \n    return ids, predictions\n\nclass_mapping = {i: f'class_{i+1}' for i in range(71)}","metadata":{"execution":{"iopub.status.busy":"2024-09-25T00:03:33.752242Z","iopub.execute_input":"2024-09-25T00:03:33.753045Z","iopub.status.idle":"2024-09-25T00:03:33.759744Z","shell.execute_reply.started":"2024-09-25T00:03:33.753003Z","shell.execute_reply":"2024-09-25T00:03:33.758774Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"ids, predictions = evaluate_model_on_test_set(model, test_loader, device, class_mapping)\nrenamed_ids = list(range(len(ids)))\nresults = pd.DataFrame({\n    'ID': renamed_ids, \n    'TARGET': predictions \n})\n\nresults.to_csv('submission16.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-25T00:03:40.086992Z","iopub.execute_input":"2024-09-25T00:03:40.087469Z","iopub.status.idle":"2024-09-25T00:03:49.774603Z","shell.execute_reply.started":"2024-09-25T00:03:40.087429Z","shell.execute_reply":"2024-09-25T00:03:49.773743Z"},"trusted":true},"execution_count":22,"outputs":[]}]}